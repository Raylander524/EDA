{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "14ebf7f4",
   "metadata": {},
   "source": [
    "# Nome: Raylander Marques Melo\n",
    "# Matrícula: 586108"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d853f877",
   "metadata": {},
   "source": [
    "## Crie um arquivo Jupyter Notebook e realize as seguintes operações:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "adf2369a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pandas\n",
      "  Using cached pandas-2.3.3-cp312-cp312-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl.metadata (91 kB)\n",
      "Collecting matplotlib\n",
      "  Using cached matplotlib-3.10.7-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (11 kB)\n",
      "Collecting numpy\n",
      "  Using cached numpy-2.3.4-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (62 kB)\n",
      "Collecting networkx\n",
      "  Using cached networkx-3.5-py3-none-any.whl.metadata (6.3 kB)\n",
      "Collecting torch\n",
      "  Using cached torch-2.9.0-cp312-cp312-manylinux_2_28_x86_64.whl.metadata (30 kB)\n",
      "Collecting sentence-transformers\n",
      "  Using cached sentence_transformers-5.1.2-py3-none-any.whl.metadata (16 kB)\n",
      "Collecting pyvis\n",
      "  Using cached pyvis-0.3.2-py3-none-any.whl.metadata (1.7 kB)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in ./.venv/lib/python3.12/site-packages (from pandas) (2.9.0.post0)\n",
      "Collecting pytz>=2020.1 (from pandas)\n",
      "  Using cached pytz-2025.2-py2.py3-none-any.whl.metadata (22 kB)\n",
      "Collecting tzdata>=2022.7 (from pandas)\n",
      "  Using cached tzdata-2025.2-py2.py3-none-any.whl.metadata (1.4 kB)\n",
      "Collecting contourpy>=1.0.1 (from matplotlib)\n",
      "  Using cached contourpy-1.3.3-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (5.5 kB)\n",
      "Collecting cycler>=0.10 (from matplotlib)\n",
      "  Using cached cycler-0.12.1-py3-none-any.whl.metadata (3.8 kB)\n",
      "Collecting fonttools>=4.22.0 (from matplotlib)\n",
      "  Using cached fonttools-4.60.1-cp312-cp312-manylinux1_x86_64.manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_5_x86_64.whl.metadata (112 kB)\n",
      "Collecting kiwisolver>=1.3.1 (from matplotlib)\n",
      "  Using cached kiwisolver-1.4.9-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (6.3 kB)\n",
      "Requirement already satisfied: packaging>=20.0 in ./.venv/lib/python3.12/site-packages (from matplotlib) (25.0)\n",
      "Collecting pillow>=8 (from matplotlib)\n",
      "  Using cached pillow-12.0.0-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (8.8 kB)\n",
      "Collecting pyparsing>=3 (from matplotlib)\n",
      "  Using cached pyparsing-3.2.5-py3-none-any.whl.metadata (5.0 kB)\n",
      "Collecting filelock (from torch)\n",
      "  Using cached filelock-3.20.0-py3-none-any.whl.metadata (2.1 kB)\n",
      "Collecting typing-extensions>=4.10.0 (from torch)\n",
      "  Using cached typing_extensions-4.15.0-py3-none-any.whl.metadata (3.3 kB)\n",
      "Collecting setuptools (from torch)\n",
      "  Using cached setuptools-80.9.0-py3-none-any.whl.metadata (6.6 kB)\n",
      "Collecting sympy>=1.13.3 (from torch)\n",
      "  Using cached sympy-1.14.0-py3-none-any.whl.metadata (12 kB)\n",
      "Collecting jinja2 (from torch)\n",
      "  Using cached jinja2-3.1.6-py3-none-any.whl.metadata (2.9 kB)\n",
      "Collecting fsspec>=0.8.5 (from torch)\n",
      "  Downloading fsspec-2025.10.0-py3-none-any.whl.metadata (10 kB)\n",
      "Collecting nvidia-cuda-nvrtc-cu12==12.8.93 (from torch)\n",
      "  Using cached nvidia_cuda_nvrtc_cu12-12.8.93-py3-none-manylinux2010_x86_64.manylinux_2_12_x86_64.whl.metadata (1.7 kB)\n",
      "Collecting nvidia-cuda-runtime-cu12==12.8.90 (from torch)\n",
      "  Using cached nvidia_cuda_runtime_cu12-12.8.90-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.7 kB)\n",
      "Collecting nvidia-cuda-cupti-cu12==12.8.90 (from torch)\n",
      "  Using cached nvidia_cuda_cupti_cu12-12.8.90-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.7 kB)\n",
      "Collecting nvidia-cudnn-cu12==9.10.2.21 (from torch)\n",
      "  Using cached nvidia_cudnn_cu12-9.10.2.21-py3-none-manylinux_2_27_x86_64.whl.metadata (1.8 kB)\n",
      "Collecting nvidia-cublas-cu12==12.8.4.1 (from torch)\n",
      "  Using cached nvidia_cublas_cu12-12.8.4.1-py3-none-manylinux_2_27_x86_64.whl.metadata (1.7 kB)\n",
      "Collecting nvidia-cufft-cu12==11.3.3.83 (from torch)\n",
      "  Using cached nvidia_cufft_cu12-11.3.3.83-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.7 kB)\n",
      "Collecting nvidia-curand-cu12==10.3.9.90 (from torch)\n",
      "  Using cached nvidia_curand_cu12-10.3.9.90-py3-none-manylinux_2_27_x86_64.whl.metadata (1.7 kB)\n",
      "Collecting nvidia-cusolver-cu12==11.7.3.90 (from torch)\n",
      "  Using cached nvidia_cusolver_cu12-11.7.3.90-py3-none-manylinux_2_27_x86_64.whl.metadata (1.8 kB)\n",
      "Collecting nvidia-cusparse-cu12==12.5.8.93 (from torch)\n",
      "  Using cached nvidia_cusparse_cu12-12.5.8.93-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.8 kB)\n",
      "Collecting nvidia-cusparselt-cu12==0.7.1 (from torch)\n",
      "  Using cached nvidia_cusparselt_cu12-0.7.1-py3-none-manylinux2014_x86_64.whl.metadata (7.0 kB)\n",
      "Collecting nvidia-nccl-cu12==2.27.5 (from torch)\n",
      "  Using cached nvidia_nccl_cu12-2.27.5-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (2.0 kB)\n",
      "Collecting nvidia-nvshmem-cu12==3.3.20 (from torch)\n",
      "  Using cached nvidia_nvshmem_cu12-3.3.20-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (2.1 kB)\n",
      "Collecting nvidia-nvtx-cu12==12.8.90 (from torch)\n",
      "  Using cached nvidia_nvtx_cu12-12.8.90-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.8 kB)\n",
      "Collecting nvidia-nvjitlink-cu12==12.8.93 (from torch)\n",
      "  Using cached nvidia_nvjitlink_cu12-12.8.93-py3-none-manylinux2010_x86_64.manylinux_2_12_x86_64.whl.metadata (1.7 kB)\n",
      "Collecting nvidia-cufile-cu12==1.13.1.3 (from torch)\n",
      "  Using cached nvidia_cufile_cu12-1.13.1.3-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.7 kB)\n",
      "Collecting triton==3.5.0 (from torch)\n",
      "  Using cached triton-3.5.0-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (1.7 kB)\n",
      "Collecting transformers<5.0.0,>=4.41.0 (from sentence-transformers)\n",
      "  Using cached transformers-4.57.1-py3-none-any.whl.metadata (43 kB)\n",
      "Collecting tqdm (from sentence-transformers)\n",
      "  Using cached tqdm-4.67.1-py3-none-any.whl.metadata (57 kB)\n",
      "Collecting scikit-learn (from sentence-transformers)\n",
      "  Using cached scikit_learn-1.7.2-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (11 kB)\n",
      "Collecting scipy (from sentence-transformers)\n",
      "  Downloading scipy-1.16.3-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (62 kB)\n",
      "Collecting huggingface-hub>=0.20.0 (from sentence-transformers)\n",
      "  Downloading huggingface_hub-1.0.1-py3-none-any.whl.metadata (13 kB)\n",
      "  Using cached huggingface_hub-0.36.0-py3-none-any.whl.metadata (14 kB)\n",
      "Collecting pyyaml>=5.1 (from transformers<5.0.0,>=4.41.0->sentence-transformers)\n",
      "  Using cached pyyaml-6.0.3-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl.metadata (2.4 kB)\n",
      "Collecting regex!=2019.12.17 (from transformers<5.0.0,>=4.41.0->sentence-transformers)\n",
      "  Downloading regex-2025.11.3-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl.metadata (40 kB)\n",
      "Collecting requests (from transformers<5.0.0,>=4.41.0->sentence-transformers)\n",
      "  Using cached requests-2.32.5-py3-none-any.whl.metadata (4.9 kB)\n",
      "Collecting tokenizers<=0.23.0,>=0.22.0 (from transformers<5.0.0,>=4.41.0->sentence-transformers)\n",
      "  Using cached tokenizers-0.22.1-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.8 kB)\n",
      "Collecting safetensors>=0.4.3 (from transformers<5.0.0,>=4.41.0->sentence-transformers)\n",
      "  Using cached safetensors-0.6.2-cp38-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.1 kB)\n",
      "Collecting hf-xet<2.0.0,>=1.1.3 (from huggingface-hub>=0.20.0->sentence-transformers)\n",
      "  Using cached hf_xet-1.2.0-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.9 kB)\n",
      "Requirement already satisfied: ipython>=5.3.0 in ./.venv/lib/python3.12/site-packages (from pyvis) (9.7.0)\n",
      "Collecting jsonpickle>=1.4.1 (from pyvis)\n",
      "  Using cached jsonpickle-4.1.1-py3-none-any.whl.metadata (8.1 kB)\n",
      "Requirement already satisfied: decorator>=4.3.2 in ./.venv/lib/python3.12/site-packages (from ipython>=5.3.0->pyvis) (5.2.1)\n",
      "Requirement already satisfied: ipython-pygments-lexers>=1.0.0 in ./.venv/lib/python3.12/site-packages (from ipython>=5.3.0->pyvis) (1.1.1)\n",
      "Requirement already satisfied: jedi>=0.18.1 in ./.venv/lib/python3.12/site-packages (from ipython>=5.3.0->pyvis) (0.19.2)\n",
      "Requirement already satisfied: matplotlib-inline>=0.1.5 in ./.venv/lib/python3.12/site-packages (from ipython>=5.3.0->pyvis) (0.2.1)\n",
      "Requirement already satisfied: pexpect>4.3 in ./.venv/lib/python3.12/site-packages (from ipython>=5.3.0->pyvis) (4.9.0)\n",
      "Requirement already satisfied: prompt_toolkit<3.1.0,>=3.0.41 in ./.venv/lib/python3.12/site-packages (from ipython>=5.3.0->pyvis) (3.0.52)\n",
      "Requirement already satisfied: pygments>=2.11.0 in ./.venv/lib/python3.12/site-packages (from ipython>=5.3.0->pyvis) (2.19.2)\n",
      "Requirement already satisfied: stack_data>=0.6.0 in ./.venv/lib/python3.12/site-packages (from ipython>=5.3.0->pyvis) (0.6.3)\n",
      "Requirement already satisfied: traitlets>=5.13.0 in ./.venv/lib/python3.12/site-packages (from ipython>=5.3.0->pyvis) (5.14.3)\n",
      "Requirement already satisfied: wcwidth in ./.venv/lib/python3.12/site-packages (from prompt_toolkit<3.1.0,>=3.0.41->ipython>=5.3.0->pyvis) (0.2.14)\n",
      "Requirement already satisfied: parso<0.9.0,>=0.8.4 in ./.venv/lib/python3.12/site-packages (from jedi>=0.18.1->ipython>=5.3.0->pyvis) (0.8.5)\n",
      "Collecting MarkupSafe>=2.0 (from jinja2->torch)\n",
      "  Using cached markupsafe-3.0.3-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl.metadata (2.7 kB)\n",
      "Requirement already satisfied: ptyprocess>=0.5 in ./.venv/lib/python3.12/site-packages (from pexpect>4.3->ipython>=5.3.0->pyvis) (0.7.0)\n",
      "Requirement already satisfied: six>=1.5 in ./.venv/lib/python3.12/site-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
      "Requirement already satisfied: executing>=1.2.0 in ./.venv/lib/python3.12/site-packages (from stack_data>=0.6.0->ipython>=5.3.0->pyvis) (2.2.1)\n",
      "Requirement already satisfied: asttokens>=2.1.0 in ./.venv/lib/python3.12/site-packages (from stack_data>=0.6.0->ipython>=5.3.0->pyvis) (3.0.0)\n",
      "Requirement already satisfied: pure-eval in ./.venv/lib/python3.12/site-packages (from stack_data>=0.6.0->ipython>=5.3.0->pyvis) (0.2.3)\n",
      "Collecting mpmath<1.4,>=1.1.0 (from sympy>=1.13.3->torch)\n",
      "  Using cached mpmath-1.3.0-py3-none-any.whl.metadata (8.6 kB)\n",
      "Collecting charset_normalizer<4,>=2 (from requests->transformers<5.0.0,>=4.41.0->sentence-transformers)\n",
      "  Using cached charset_normalizer-3.4.4-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl.metadata (37 kB)\n",
      "Collecting idna<4,>=2.5 (from requests->transformers<5.0.0,>=4.41.0->sentence-transformers)\n",
      "  Using cached idna-3.11-py3-none-any.whl.metadata (8.4 kB)\n",
      "Collecting urllib3<3,>=1.21.1 (from requests->transformers<5.0.0,>=4.41.0->sentence-transformers)\n",
      "  Using cached urllib3-2.5.0-py3-none-any.whl.metadata (6.5 kB)\n",
      "Collecting certifi>=2017.4.17 (from requests->transformers<5.0.0,>=4.41.0->sentence-transformers)\n",
      "  Using cached certifi-2025.10.5-py3-none-any.whl.metadata (2.5 kB)\n",
      "Collecting joblib>=1.2.0 (from scikit-learn->sentence-transformers)\n",
      "  Using cached joblib-1.5.2-py3-none-any.whl.metadata (5.6 kB)\n",
      "Collecting threadpoolctl>=3.1.0 (from scikit-learn->sentence-transformers)\n",
      "  Using cached threadpoolctl-3.6.0-py3-none-any.whl.metadata (13 kB)\n",
      "Using cached pandas-2.3.3-cp312-cp312-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl (12.4 MB)\n",
      "Using cached matplotlib-3.10.7-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (8.7 MB)\n",
      "Using cached numpy-2.3.4-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (16.6 MB)\n",
      "Using cached networkx-3.5-py3-none-any.whl (2.0 MB)\n",
      "Using cached torch-2.9.0-cp312-cp312-manylinux_2_28_x86_64.whl (899.7 MB)\n",
      "Using cached nvidia_cublas_cu12-12.8.4.1-py3-none-manylinux_2_27_x86_64.whl (594.3 MB)\n",
      "Using cached nvidia_cuda_cupti_cu12-12.8.90-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (10.2 MB)\n",
      "Using cached nvidia_cuda_nvrtc_cu12-12.8.93-py3-none-manylinux2010_x86_64.manylinux_2_12_x86_64.whl (88.0 MB)\n",
      "Using cached nvidia_cuda_runtime_cu12-12.8.90-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (954 kB)\n",
      "Using cached nvidia_cudnn_cu12-9.10.2.21-py3-none-manylinux_2_27_x86_64.whl (706.8 MB)\n",
      "Using cached nvidia_cufft_cu12-11.3.3.83-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (193.1 MB)\n",
      "Using cached nvidia_cufile_cu12-1.13.1.3-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (1.2 MB)\n",
      "Using cached nvidia_curand_cu12-10.3.9.90-py3-none-manylinux_2_27_x86_64.whl (63.6 MB)\n",
      "Using cached nvidia_cusolver_cu12-11.7.3.90-py3-none-manylinux_2_27_x86_64.whl (267.5 MB)\n",
      "Using cached nvidia_cusparse_cu12-12.5.8.93-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (288.2 MB)\n",
      "Using cached nvidia_cusparselt_cu12-0.7.1-py3-none-manylinux2014_x86_64.whl (287.2 MB)\n",
      "Using cached nvidia_nccl_cu12-2.27.5-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (322.3 MB)\n",
      "Using cached nvidia_nvjitlink_cu12-12.8.93-py3-none-manylinux2010_x86_64.manylinux_2_12_x86_64.whl (39.3 MB)\n",
      "Using cached nvidia_nvshmem_cu12-3.3.20-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (124.7 MB)\n",
      "Using cached nvidia_nvtx_cu12-12.8.90-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (89 kB)\n",
      "Using cached triton-3.5.0-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (170.5 MB)\n",
      "Using cached sentence_transformers-5.1.2-py3-none-any.whl (488 kB)\n",
      "Using cached transformers-4.57.1-py3-none-any.whl (12.0 MB)\n",
      "Using cached huggingface_hub-0.36.0-py3-none-any.whl (566 kB)\n",
      "Using cached hf_xet-1.2.0-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.3 MB)\n",
      "Using cached tokenizers-0.22.1-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.3 MB)\n",
      "Using cached pyvis-0.3.2-py3-none-any.whl (756 kB)\n",
      "Using cached contourpy-1.3.3-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (362 kB)\n",
      "Using cached cycler-0.12.1-py3-none-any.whl (8.3 kB)\n",
      "Using cached fonttools-4.60.1-cp312-cp312-manylinux1_x86_64.manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_5_x86_64.whl (4.9 MB)\n",
      "Downloading fsspec-2025.10.0-py3-none-any.whl (200 kB)\n",
      "Using cached jinja2-3.1.6-py3-none-any.whl (134 kB)\n",
      "Using cached jsonpickle-4.1.1-py3-none-any.whl (47 kB)\n",
      "Using cached kiwisolver-1.4.9-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (1.5 MB)\n",
      "Using cached markupsafe-3.0.3-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl (22 kB)\n",
      "Using cached pillow-12.0.0-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (7.0 MB)\n",
      "Using cached pyparsing-3.2.5-py3-none-any.whl (113 kB)\n",
      "Using cached pytz-2025.2-py2.py3-none-any.whl (509 kB)\n",
      "Using cached pyyaml-6.0.3-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl (807 kB)\n",
      "Downloading regex-2025.11.3-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl (803 kB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m803.5/803.5 kB\u001b[0m \u001b[31m268.7 kB/s\u001b[0m  \u001b[33m0:00:02\u001b[0m \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hUsing cached safetensors-0.6.2-cp38-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (485 kB)\n",
      "Using cached sympy-1.14.0-py3-none-any.whl (6.3 MB)\n",
      "Using cached mpmath-1.3.0-py3-none-any.whl (536 kB)\n",
      "Using cached tqdm-4.67.1-py3-none-any.whl (78 kB)\n",
      "Using cached typing_extensions-4.15.0-py3-none-any.whl (44 kB)\n",
      "Using cached tzdata-2025.2-py2.py3-none-any.whl (347 kB)\n",
      "Using cached filelock-3.20.0-py3-none-any.whl (16 kB)\n",
      "Using cached requests-2.32.5-py3-none-any.whl (64 kB)\n",
      "Using cached charset_normalizer-3.4.4-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl (153 kB)\n",
      "Using cached idna-3.11-py3-none-any.whl (71 kB)\n",
      "Using cached urllib3-2.5.0-py3-none-any.whl (129 kB)\n",
      "Using cached certifi-2025.10.5-py3-none-any.whl (163 kB)\n",
      "Using cached scikit_learn-1.7.2-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (9.5 MB)\n",
      "Using cached joblib-1.5.2-py3-none-any.whl (308 kB)\n",
      "Downloading scipy-1.16.3-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (35.7 MB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m35.7/35.7 MB\u001b[0m \u001b[31m13.9 MB/s\u001b[0m  \u001b[33m0:00:02\u001b[0m\u001b[0m eta \u001b[36m0:00:01\u001b[0m[36m0:00:01\u001b[0m\n",
      "\u001b[?25hUsing cached threadpoolctl-3.6.0-py3-none-any.whl (18 kB)\n",
      "Using cached setuptools-80.9.0-py3-none-any.whl (1.2 MB)\n",
      "Installing collected packages: pytz, nvidia-cusparselt-cu12, mpmath, urllib3, tzdata, typing-extensions, triton, tqdm, threadpoolctl, sympy, setuptools, safetensors, regex, pyyaml, pyparsing, pillow, nvidia-nvtx-cu12, nvidia-nvshmem-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufile-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, numpy, networkx, MarkupSafe, kiwisolver, jsonpickle, joblib, idna, hf-xet, fsspec, fonttools, filelock, cycler, charset_normalizer, certifi, scipy, requests, pandas, nvidia-cusparse-cu12, nvidia-cufft-cu12, nvidia-cudnn-cu12, jinja2, contourpy, scikit-learn, pyvis, nvidia-cusolver-cu12, matplotlib, huggingface-hub, torch, tokenizers, transformers, sentence-transformers\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m57/57\u001b[0m [sentence-transformers]e-transformers]transformers]]u12]]u12]\n",
      "\u001b[1A\u001b[2KSuccessfully installed MarkupSafe-3.0.3 certifi-2025.10.5 charset_normalizer-3.4.4 contourpy-1.3.3 cycler-0.12.1 filelock-3.20.0 fonttools-4.60.1 fsspec-2025.10.0 hf-xet-1.2.0 huggingface-hub-0.36.0 idna-3.11 jinja2-3.1.6 joblib-1.5.2 jsonpickle-4.1.1 kiwisolver-1.4.9 matplotlib-3.10.7 mpmath-1.3.0 networkx-3.5 numpy-2.3.4 nvidia-cublas-cu12-12.8.4.1 nvidia-cuda-cupti-cu12-12.8.90 nvidia-cuda-nvrtc-cu12-12.8.93 nvidia-cuda-runtime-cu12-12.8.90 nvidia-cudnn-cu12-9.10.2.21 nvidia-cufft-cu12-11.3.3.83 nvidia-cufile-cu12-1.13.1.3 nvidia-curand-cu12-10.3.9.90 nvidia-cusolver-cu12-11.7.3.90 nvidia-cusparse-cu12-12.5.8.93 nvidia-cusparselt-cu12-0.7.1 nvidia-nccl-cu12-2.27.5 nvidia-nvjitlink-cu12-12.8.93 nvidia-nvshmem-cu12-3.3.20 nvidia-nvtx-cu12-12.8.90 pandas-2.3.3 pillow-12.0.0 pyparsing-3.2.5 pytz-2025.2 pyvis-0.3.2 pyyaml-6.0.3 regex-2025.11.3 requests-2.32.5 safetensors-0.6.2 scikit-learn-1.7.2 scipy-1.16.3 sentence-transformers-5.1.2 setuptools-80.9.0 sympy-1.14.0 threadpoolctl-3.6.0 tokenizers-0.22.1 torch-2.9.0 tqdm-4.67.1 transformers-4.57.1 triton-3.5.0 typing-extensions-4.15.0 tzdata-2025.2 urllib3-2.5.0\n"
     ]
    }
   ],
   "source": [
    "!pip install pandas matplotlib numpy networkx torch sentence-transformers pyvis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3e9c6ae9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/raylander/Desktop/EDA/Lista 4/.venv/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpandas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpd\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msentence_transformers\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m SentenceTransformer, util\n\u001b[32m      3\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnetworkx\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnx\u001b[39;00m\n\u001b[32m      4\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpyvis\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mnetwork\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Network\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/EDA/Lista 4/.venv/lib/python3.12/site-packages/sentence_transformers/__init__.py:15\u001b[39m\n\u001b[32m      8\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mwarnings\u001b[39;00m\n\u001b[32m     10\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msentence_transformers\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mbackend\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[32m     11\u001b[39m     export_dynamic_quantized_onnx_model,\n\u001b[32m     12\u001b[39m     export_optimized_onnx_model,\n\u001b[32m     13\u001b[39m     export_static_quantized_openvino_model,\n\u001b[32m     14\u001b[39m )\n\u001b[32m---> \u001b[39m\u001b[32m15\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msentence_transformers\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mcross_encoder\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[32m     16\u001b[39m     CrossEncoder,\n\u001b[32m     17\u001b[39m     CrossEncoderModelCardData,\n\u001b[32m     18\u001b[39m     CrossEncoderTrainer,\n\u001b[32m     19\u001b[39m     CrossEncoderTrainingArguments,\n\u001b[32m     20\u001b[39m )\n\u001b[32m     21\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msentence_transformers\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mdatasets\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m ParallelSentencesDataset, SentencesDataset\n\u001b[32m     22\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msentence_transformers\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mLoggingHandler\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m LoggingHandler\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/EDA/Lista 4/.venv/lib/python3.12/site-packages/sentence_transformers/cross_encoder/__init__.py:3\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m__future__\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m annotations\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mCrossEncoder\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m CrossEncoder\n\u001b[32m      4\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mmodel_card\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m CrossEncoderModelCardData\n\u001b[32m      5\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mtrainer\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m CrossEncoderTrainer\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/EDA/Lista 4/.venv/lib/python3.12/site-packages/sentence_transformers/cross_encoder/CrossEncoder.py:16\u001b[39m\n\u001b[32m     14\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtorch\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m nn\n\u001b[32m     15\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtqdm\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mautonotebook\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m trange\n\u001b[32m---> \u001b[39m\u001b[32m16\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtransformers\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[32m     17\u001b[39m     AutoConfig,\n\u001b[32m     18\u001b[39m     AutoModelForSequenceClassification,\n\u001b[32m     19\u001b[39m     AutoTokenizer,\n\u001b[32m     20\u001b[39m     PretrainedConfig,\n\u001b[32m     21\u001b[39m     PreTrainedModel,\n\u001b[32m     22\u001b[39m     PreTrainedTokenizer,\n\u001b[32m     23\u001b[39m )\n\u001b[32m     24\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtransformers\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mutils\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m PushToHubMixin\n\u001b[32m     25\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtyping_extensions\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m deprecated\n",
      "\u001b[36mFile \u001b[39m\u001b[32m<frozen importlib._bootstrap>:1412\u001b[39m, in \u001b[36m_handle_fromlist\u001b[39m\u001b[34m(module, fromlist, import_, recursive)\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/EDA/Lista 4/.venv/lib/python3.12/site-packages/transformers/utils/import_utils.py:2317\u001b[39m, in \u001b[36m_LazyModule.__getattr__\u001b[39m\u001b[34m(self, name)\u001b[39m\n\u001b[32m   2315\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m name \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m._class_to_module:\n\u001b[32m   2316\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m2317\u001b[39m         module = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_get_module\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_class_to_module\u001b[49m\u001b[43m[\u001b[49m\u001b[43mname\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   2318\u001b[39m         value = \u001b[38;5;28mgetattr\u001b[39m(module, name)\n\u001b[32m   2319\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m (\u001b[38;5;167;01mModuleNotFoundError\u001b[39;00m, \u001b[38;5;167;01mRuntimeError\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/EDA/Lista 4/.venv/lib/python3.12/site-packages/transformers/utils/import_utils.py:2345\u001b[39m, in \u001b[36m_LazyModule._get_module\u001b[39m\u001b[34m(self, module_name)\u001b[39m\n\u001b[32m   2343\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_get_module\u001b[39m(\u001b[38;5;28mself\u001b[39m, module_name: \u001b[38;5;28mstr\u001b[39m):\n\u001b[32m   2344\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m2345\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mimportlib\u001b[49m\u001b[43m.\u001b[49m\u001b[43mimport_module\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m.\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m+\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodule_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[34;43m__name__\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m   2346\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m   2347\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m e\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/lib/python3.12/importlib/__init__.py:90\u001b[39m, in \u001b[36mimport_module\u001b[39m\u001b[34m(name, package)\u001b[39m\n\u001b[32m     88\u001b[39m             \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[32m     89\u001b[39m         level += \u001b[32m1\u001b[39m\n\u001b[32m---> \u001b[39m\u001b[32m90\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_bootstrap\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_gcd_import\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m[\u001b[49m\u001b[43mlevel\u001b[49m\u001b[43m:\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpackage\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlevel\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/EDA/Lista 4/.venv/lib/python3.12/site-packages/transformers/models/auto/modeling_auto.py:23\u001b[39m\n\u001b[32m     20\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtyping\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m TYPE_CHECKING, Union\n\u001b[32m     22\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mutils\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m logging\n\u001b[32m---> \u001b[39m\u001b[32m23\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mauto_factory\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[32m     24\u001b[39m     _BaseAutoBackboneClass,\n\u001b[32m     25\u001b[39m     _BaseAutoModelClass,\n\u001b[32m     26\u001b[39m     _LazyAutoMapping,\n\u001b[32m     27\u001b[39m     auto_class_update,\n\u001b[32m     28\u001b[39m )\n\u001b[32m     29\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mconfiguration_auto\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m CONFIG_MAPPING_NAMES\n\u001b[32m     32\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m TYPE_CHECKING:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/EDA/Lista 4/.venv/lib/python3.12/site-packages/transformers/models/auto/auto_factory.py:43\u001b[39m\n\u001b[32m     39\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mconfiguration_auto\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m AutoConfig, model_type_to_module_name, replace_list_option_in_docstrings\n\u001b[32m     42\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m is_torch_available():\n\u001b[32m---> \u001b[39m\u001b[32m43\u001b[39m     \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mgeneration\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m GenerationMixin\n\u001b[32m     46\u001b[39m logger = logging.get_logger(\u001b[34m__name__\u001b[39m)\n\u001b[32m     48\u001b[39m _T = TypeVar(\u001b[33m\"\u001b[39m\u001b[33m_T\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m<frozen importlib._bootstrap>:1412\u001b[39m, in \u001b[36m_handle_fromlist\u001b[39m\u001b[34m(module, fromlist, import_, recursive)\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/EDA/Lista 4/.venv/lib/python3.12/site-packages/transformers/utils/import_utils.py:2317\u001b[39m, in \u001b[36m_LazyModule.__getattr__\u001b[39m\u001b[34m(self, name)\u001b[39m\n\u001b[32m   2315\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m name \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m._class_to_module:\n\u001b[32m   2316\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m2317\u001b[39m         module = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_get_module\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_class_to_module\u001b[49m\u001b[43m[\u001b[49m\u001b[43mname\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   2318\u001b[39m         value = \u001b[38;5;28mgetattr\u001b[39m(module, name)\n\u001b[32m   2319\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m (\u001b[38;5;167;01mModuleNotFoundError\u001b[39;00m, \u001b[38;5;167;01mRuntimeError\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/EDA/Lista 4/.venv/lib/python3.12/site-packages/transformers/utils/import_utils.py:2345\u001b[39m, in \u001b[36m_LazyModule._get_module\u001b[39m\u001b[34m(self, module_name)\u001b[39m\n\u001b[32m   2343\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_get_module\u001b[39m(\u001b[38;5;28mself\u001b[39m, module_name: \u001b[38;5;28mstr\u001b[39m):\n\u001b[32m   2344\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m2345\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mimportlib\u001b[49m\u001b[43m.\u001b[49m\u001b[43mimport_module\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m.\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m+\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodule_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[34;43m__name__\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m   2346\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m   2347\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m e\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/lib/python3.12/importlib/__init__.py:90\u001b[39m, in \u001b[36mimport_module\u001b[39m\u001b[34m(name, package)\u001b[39m\n\u001b[32m     88\u001b[39m             \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[32m     89\u001b[39m         level += \u001b[32m1\u001b[39m\n\u001b[32m---> \u001b[39m\u001b[32m90\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_bootstrap\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_gcd_import\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m[\u001b[49m\u001b[43mlevel\u001b[49m\u001b[43m:\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpackage\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlevel\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/EDA/Lista 4/.venv/lib/python3.12/site-packages/transformers/generation/utils.py:43\u001b[39m\n\u001b[32m     41\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mintegrations\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mdeepspeed\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m is_deepspeed_zero3_enabled\n\u001b[32m     42\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mintegrations\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mfsdp\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m is_fsdp_managed_module\n\u001b[32m---> \u001b[39m\u001b[32m43\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mmasking_utils\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m create_masks_for_generate\n\u001b[32m     44\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mpytorch_utils\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m isin_mps_friendly\n\u001b[32m     45\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mtokenization_utils\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m ExtensionsTrie\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/EDA/Lista 4/.venv/lib/python3.12/site-packages/transformers/masking_utils.py:40\u001b[39m\n\u001b[32m     37\u001b[39m _is_torch_xpu_available = is_torch_xpu_available()\n\u001b[32m     39\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m _is_torch_greater_or_equal_than_2_6:\n\u001b[32m---> \u001b[39m\u001b[32m40\u001b[39m     \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtorch\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01m_dynamo\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01m_trace_wrapped_higher_order_op\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m TransformGetItemToIndex\n\u001b[32m     43\u001b[39m logger = logging.get_logger(\u001b[34m__name__\u001b[39m)\n\u001b[32m     46\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mand_masks\u001b[39m(*mask_functions: Callable) -> Callable:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/EDA/Lista 4/.venv/lib/python3.12/site-packages/torch/_dynamo/__init__.py:13\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m      2\u001b[39m \u001b[33;03mTorchDynamo is a Python-level JIT compiler designed to make unmodified PyTorch programs faster.\u001b[39;00m\n\u001b[32m      3\u001b[39m \u001b[33;03mTorchDynamo hooks into the frame evaluation API in CPython (PEP 523) to dynamically modify Python\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m      8\u001b[39m \u001b[33;03mseamlessly optimize PyTorch programs, including those using modern Python features.\u001b[39;00m\n\u001b[32m      9\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m     11\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtorch\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m13\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[32m     14\u001b[39m     aot_compile,\n\u001b[32m     15\u001b[39m     config,\n\u001b[32m     16\u001b[39m     convert_frame,\n\u001b[32m     17\u001b[39m     eval_frame,\n\u001b[32m     18\u001b[39m     functional_export,\n\u001b[32m     19\u001b[39m     resume_execution,\n\u001b[32m     20\u001b[39m )\n\u001b[32m     21\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mbackends\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mregistry\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m list_backends, lookup_backend, register_backend\n\u001b[32m     22\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mcallback\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m callback_handler, on_compile_end, on_compile_start\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/EDA/Lista 4/.venv/lib/python3.12/site-packages/torch/_dynamo/aot_compile.py:15\u001b[39m\n\u001b[32m     12\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtorch\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mfx\u001b[39;00m\n\u001b[32m     13\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtorch\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01m_dynamo\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mprecompile_context\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m PrecompileContext\n\u001b[32m---> \u001b[39m\u001b[32m15\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m convert_frame\n\u001b[32m     16\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mhooks\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Hooks\n\u001b[32m     19\u001b[39m log = logging.getLogger(\u001b[34m__name__\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/EDA/Lista 4/.venv/lib/python3.12/site-packages/torch/_dynamo/convert_frame.py:57\u001b[39m\n\u001b[32m     55\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtorch\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01m_dynamo\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mcallback\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m CallbackTrigger\n\u001b[32m     56\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtorch\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01m_dynamo\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mdistributed\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m get_compile_pg\n\u001b[32m---> \u001b[39m\u001b[32m57\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtorch\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01m_dynamo\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01msymbolic_convert\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m TensorifyState\n\u001b[32m     58\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtorch\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01m_guards\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m compile_context, CompileContext, CompileId, tracing\n\u001b[32m     59\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtorch\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01m_logging\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m structured\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/EDA/Lista 4/.venv/lib/python3.12/site-packages/torch/_dynamo/symbolic_convert.py:53\u001b[39m\n\u001b[32m     51\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtorch\u001b[39;00m\n\u001b[32m     52\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtorch\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01m_logging\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m53\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtorch\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01m_dynamo\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mexc\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m ObservedException, TensorifyScalarRestartAnalysis\n\u001b[32m     54\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtorch\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01m_guards\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m tracing, TracingContext\n\u001b[32m     55\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtorch\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01m_logging\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mstructured\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m dump_file\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/EDA/Lista 4/.venv/lib/python3.12/site-packages/torch/_dynamo/exc.py:45\u001b[39m\n\u001b[32m     42\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtorch\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01m_utils_internal\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m get_file_path_2\n\u001b[32m     44\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m config\n\u001b[32m---> \u001b[39m\u001b[32m45\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mutils\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m counters\n\u001b[32m     48\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m TYPE_CHECKING:\n\u001b[32m     49\u001b[39m     \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtypes\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/EDA/Lista 4/.venv/lib/python3.12/site-packages/torch/_dynamo/utils.py:2414\u001b[39m\n\u001b[32m   2389\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m fn\n\u001b[32m   2392\u001b[39m common_constant_types: \u001b[38;5;28mset\u001b[39m[\u001b[38;5;28mtype\u001b[39m] = {\n\u001b[32m   2393\u001b[39m     \u001b[38;5;28mint\u001b[39m,\n\u001b[32m   2394\u001b[39m     \u001b[38;5;28mfloat\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m   2411\u001b[39m     torch.cuda._CudaDeviceProperties,\n\u001b[32m   2412\u001b[39m }\n\u001b[32m-> \u001b[39m\u001b[32m2414\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[43mhas_triton_package\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[32m   2415\u001b[39m     \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtriton\u001b[39;00m\n\u001b[32m   2417\u001b[39m     common_constant_types.add(triton.language.dtype)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/EDA/Lista 4/.venv/lib/python3.12/site-packages/torch/utils/_triton.py:9\u001b[39m, in \u001b[36mhas_triton_package\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m      6\u001b[39m \u001b[38;5;129m@functools\u001b[39m.cache\n\u001b[32m      7\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mhas_triton_package\u001b[39m() -> \u001b[38;5;28mbool\u001b[39m:\n\u001b[32m      8\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m----> \u001b[39m\u001b[32m9\u001b[39m         \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtriton\u001b[39;00m  \u001b[38;5;66;03m# noqa: F401\u001b[39;00m\n\u001b[32m     11\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[32m     12\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/EDA/Lista 4/.venv/lib/python3.12/site-packages/triton/__init__.py:8\u001b[39m\n\u001b[32m      2\u001b[39m __version__ = \u001b[33m'\u001b[39m\u001b[33m3.5.0\u001b[39m\u001b[33m'\u001b[39m\n\u001b[32m      4\u001b[39m \u001b[38;5;66;03m# ---------------------------------------\u001b[39;00m\n\u001b[32m      5\u001b[39m \u001b[38;5;66;03m# Note: import order is significant here.\u001b[39;00m\n\u001b[32m      6\u001b[39m \n\u001b[32m      7\u001b[39m \u001b[38;5;66;03m# submodules\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m8\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mruntime\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[32m      9\u001b[39m     autotune,\n\u001b[32m     10\u001b[39m     Config,\n\u001b[32m     11\u001b[39m     heuristics,\n\u001b[32m     12\u001b[39m     JITFunction,\n\u001b[32m     13\u001b[39m     KernelInterface,\n\u001b[32m     14\u001b[39m     reinterpret,\n\u001b[32m     15\u001b[39m     TensorWrapper,\n\u001b[32m     16\u001b[39m     OutOfResources,\n\u001b[32m     17\u001b[39m     InterpreterError,\n\u001b[32m     18\u001b[39m     MockTensor,\n\u001b[32m     19\u001b[39m )\n\u001b[32m     20\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mruntime\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mjit\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m constexpr_function, jit\n\u001b[32m     21\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mruntime\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01m_async_compile\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m AsyncCompileMode, FutureKernel\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/EDA/Lista 4/.venv/lib/python3.12/site-packages/triton/runtime/__init__.py:1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mautotuner\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (Autotuner, Config, Heuristics, autotune, heuristics)\n\u001b[32m      2\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mcache\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m RedisRemoteCacheBackend, RemoteCacheBackend\n\u001b[32m      3\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mdriver\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m driver\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/EDA/Lista 4/.venv/lib/python3.12/site-packages/triton/runtime/autotuner.py:11\u001b[39m\n\u001b[32m      8\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mfunctools\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m cached_property\n\u001b[32m      9\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtyping\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Dict, Tuple, List, Optional\n\u001b[32m---> \u001b[39m\u001b[32m11\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m knobs\n\u001b[32m     12\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mjit\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m KernelInterface, JITFunction\n\u001b[32m     13\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01merrors\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m OutOfResources, PTXASError\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/EDA/Lista 4/.venv/lib/python3.12/site-packages/triton/knobs.py:14\u001b[39m\n\u001b[32m     11\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mcontextlib\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m contextmanager\n\u001b[32m     12\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtyping\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m cast, Any, Callable, Generator, Generic, Optional, Protocol, Type, TypeVar, TypedDict, TYPE_CHECKING, Union\n\u001b[32m---> \u001b[39m\u001b[32m14\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtriton\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01m_C\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mlibtriton\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m getenv, getenv_bool  \u001b[38;5;66;03m# type: ignore\u001b[39;00m\n\u001b[32m     16\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m TYPE_CHECKING:\n\u001b[32m     17\u001b[39m     \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mruntime\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mcache\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m CacheManager, RemoteCacheBackend\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sentence_transformers import SentenceTransformer, util\n",
    "import networkx as nx\n",
    "from pyvis.network import Network\n",
    "import webbrowser\n",
    "\n",
    "import networkx as nx\n",
    "import numpy as np\n",
    "import torch\n",
    "from itertools import combinations\n",
    "from collections import defaultdict\n",
    "from datetime import timedelta\n",
    "\n",
    "# community algorithms and quality\n",
    "from networkx.algorithms import community as nx_comm\n",
    "from networkx.algorithms.community import quality as nx_quality"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ccf8c1d",
   "metadata": {},
   "source": [
    "### a)  Ler o dataset fakeTelegram.BR_2022.csv, o qual está disponível no link a seguir: https://drive.google.com/file/d/1c_hLzk85pYw-huHSnFYZM_gn-dUsYRDm/view?usp=drive_link"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cc63cd6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date_message</th>\n",
       "      <th>id_member_anonymous</th>\n",
       "      <th>id_group_anonymous</th>\n",
       "      <th>media</th>\n",
       "      <th>media_type</th>\n",
       "      <th>media_url</th>\n",
       "      <th>has_media</th>\n",
       "      <th>has_media_url</th>\n",
       "      <th>trava_zap</th>\n",
       "      <th>text_content_anonymous</th>\n",
       "      <th>...</th>\n",
       "      <th>media_name</th>\n",
       "      <th>media_md5</th>\n",
       "      <th>caracteres</th>\n",
       "      <th>words</th>\n",
       "      <th>viral</th>\n",
       "      <th>sharings</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>is_misinformation</th>\n",
       "      <th>word_count</th>\n",
       "      <th>message</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2022-10-05 06:25:04</td>\n",
       "      <td>1078cc958f0febe28f4d03207660715f</td>\n",
       "      <td>12283e08a2eb5789201e105b34489ee7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>Então é Fato Renato o áudio que eu ouvi no wha...</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>110</td>\n",
       "      <td>20</td>\n",
       "      <td>False</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>20</td>\n",
       "      <td>Então é Fato Renato o áudio que eu ouvi no wha...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2022-10-05 06:26:28</td>\n",
       "      <td>92a2d8fd7144074f659d1d29dc3751da</td>\n",
       "      <td>9f2d7394334eb224c061c9740b5748fc</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>É isso, nossa parte já foi quase toda feita. N...</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>350</td>\n",
       "      <td>59</td>\n",
       "      <td>False</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1</td>\n",
       "      <td>False</td>\n",
       "      <td>59</td>\n",
       "      <td>É isso, nossa parte já foi quase toda feita. N...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2022-10-05 06:27:28</td>\n",
       "      <td>d60aa38f62b4977426b70944af4aff72</td>\n",
       "      <td>c8f2de56550ed0bf85249608b7ead93d</td>\n",
       "      <td>94dca4cda503100ebfda7ce2bcc060eb.jpg</td>\n",
       "      <td>image/jpg</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>GENTE ACHEI ELES EM UMA SEITA MAÇONÁRICA</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>94dca4cda503100ebfda7ce2bcc060eb</td>\n",
       "      <td>40</td>\n",
       "      <td>7</td>\n",
       "      <td>False</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>7</td>\n",
       "      <td>GENTE ACHEI ELES EM UMA SEITA MAÇONÁRICA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2022-10-05 06:29:09</td>\n",
       "      <td>3b685d44ff197b98d7c9e99b8f6b5281</td>\n",
       "      <td>b52442a5fbc459ae590dca0d215e32f9</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>*SE ALGUÉM TE PERGUNTAR O QUE FOI QUE BOLSONAR...</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3669</td>\n",
       "      <td>618</td>\n",
       "      <td>False</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>618</td>\n",
       "      <td>*SE ALGUÉM TE PERGUNTAR O QUE FOI QUE BOLSONAR...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2022-10-05 06:29:48</td>\n",
       "      <td>a7e85072244cae15446c9d517dc01a1a</td>\n",
       "      <td>b8a8737812c7fd7d3e0bdbb65ef6306f</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>www.marketingdigitalparavencer.com.br</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>O Deputado Federal pelo NOVO e que foi candida...</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1242</td>\n",
       "      <td>153</td>\n",
       "      <td>False</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1</td>\n",
       "      <td>False</td>\n",
       "      <td>153</td>\n",
       "      <td>O Deputado Federal pelo NOVO e que foi candida...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>135101</th>\n",
       "      <td>2022-11-11 12:05:39</td>\n",
       "      <td>3e49fd40fd973ee1b8f1a6d58feb4a54</td>\n",
       "      <td>4c6519d965020abc048521dfa837b9bb</td>\n",
       "      <td>1e57044095e6cb86bc7373b1a6bdf035.jpg</td>\n",
       "      <td>image/jpg</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>SOMOS TRADERS PROFISSIONAIS COM MAIS DE 20 ANO...</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1e57044095e6cb86bc7373b1a6bdf035</td>\n",
       "      <td>140</td>\n",
       "      <td>23</td>\n",
       "      <td>True</td>\n",
       "      <td>13.0</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>23</td>\n",
       "      <td>SOMOS TRADERS PROFISSIONAIS COM MAIS DE 20 ANO...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>135102</th>\n",
       "      <td>2022-11-11 12:05:38</td>\n",
       "      <td>333e9869f23dbd4682d1be382d9c1e59</td>\n",
       "      <td>e56ec342fc599ebb4ed89655eb6f03aa</td>\n",
       "      <td>c59e2cebce8773795fb965bdbcc4d277.jpg</td>\n",
       "      <td>url</td>\n",
       "      <td>https://terrabrasilnoticias.com/2022/11/deputa...</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>Deputado é reeleito nos Estados Unidos, mas mo...</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>c59e2cebce8773795fb965bdbcc4d277</td>\n",
       "      <td>162</td>\n",
       "      <td>13</td>\n",
       "      <td>False</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>13</td>\n",
       "      <td>Deputado é reeleito nos Estados Unidos, mas mo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>135103</th>\n",
       "      <td>2022-11-11 12:05:56</td>\n",
       "      <td>3e49fd40fd973ee1b8f1a6d58feb4a54</td>\n",
       "      <td>4c6519d965020abc048521dfa837b9bb</td>\n",
       "      <td>3811191d6ad4e71cb7e492bf6ef22a8e.jpg</td>\n",
       "      <td>image/jpg</td>\n",
       "      <td>https://t.me/Manager_Marcus_Chat_Up_Now</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>ENVIE SEU PEDIDO !!!\\n\\nOI ?\\n\\nOLÁ ?\\n\\nQUÃO?...</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3811191d6ad4e71cb7e492bf6ef22a8e</td>\n",
       "      <td>287</td>\n",
       "      <td>42</td>\n",
       "      <td>True</td>\n",
       "      <td>63.0</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>42</td>\n",
       "      <td>ENVIE SEU PEDIDO !!!\\n\\nOI ?\\n\\nOLÁ ?\\n\\nQUÃO?...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>135104</th>\n",
       "      <td>2022-11-11 12:05:41</td>\n",
       "      <td>3e49fd40fd973ee1b8f1a6d58feb4a54</td>\n",
       "      <td>4c6519d965020abc048521dfa837b9bb</td>\n",
       "      <td>9dd3b338a07226a04f97df82fbbcb36b.jpg</td>\n",
       "      <td>image/jpg</td>\n",
       "      <td>https://t.me/Manager_Marcus_Chat_Up_Now</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>NOVOS MEMBROS SEMPRE CLICAM NO LINK DO ADMINIS...</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9dd3b338a07226a04f97df82fbbcb36b</td>\n",
       "      <td>254</td>\n",
       "      <td>28</td>\n",
       "      <td>True</td>\n",
       "      <td>12.0</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>28</td>\n",
       "      <td>NOVOS MEMBROS SEMPRE CLICAM NO LINK DO ADMINIS...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>135105</th>\n",
       "      <td>2022-11-11 12:06:15</td>\n",
       "      <td>333e9869f23dbd4682d1be382d9c1e59</td>\n",
       "      <td>e56ec342fc599ebb4ed89655eb6f03aa</td>\n",
       "      <td>25e43b6a58b848c43ad5b5f9e979822a.jpg</td>\n",
       "      <td>url</td>\n",
       "      <td>https://terrabrasilnoticias.com/2022/11/bndes-...</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>BNDES tem lucro de R$ 9,6 bilhões no terceiro ...</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>25e43b6a58b848c43ad5b5f9e979822a</td>\n",
       "      <td>152</td>\n",
       "      <td>12</td>\n",
       "      <td>False</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>12</td>\n",
       "      <td>BNDES tem lucro de R$ 9,6 bilhões no terceiro ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>135106 rows × 27 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               date_message               id_member_anonymous  \\\n",
       "0       2022-10-05 06:25:04  1078cc958f0febe28f4d03207660715f   \n",
       "1       2022-10-05 06:26:28  92a2d8fd7144074f659d1d29dc3751da   \n",
       "2       2022-10-05 06:27:28  d60aa38f62b4977426b70944af4aff72   \n",
       "3       2022-10-05 06:29:09  3b685d44ff197b98d7c9e99b8f6b5281   \n",
       "4       2022-10-05 06:29:48  a7e85072244cae15446c9d517dc01a1a   \n",
       "...                     ...                               ...   \n",
       "135101  2022-11-11 12:05:39  3e49fd40fd973ee1b8f1a6d58feb4a54   \n",
       "135102  2022-11-11 12:05:38  333e9869f23dbd4682d1be382d9c1e59   \n",
       "135103  2022-11-11 12:05:56  3e49fd40fd973ee1b8f1a6d58feb4a54   \n",
       "135104  2022-11-11 12:05:41  3e49fd40fd973ee1b8f1a6d58feb4a54   \n",
       "135105  2022-11-11 12:06:15  333e9869f23dbd4682d1be382d9c1e59   \n",
       "\n",
       "                      id_group_anonymous  \\\n",
       "0       12283e08a2eb5789201e105b34489ee7   \n",
       "1       9f2d7394334eb224c061c9740b5748fc   \n",
       "2       c8f2de56550ed0bf85249608b7ead93d   \n",
       "3       b52442a5fbc459ae590dca0d215e32f9   \n",
       "4       b8a8737812c7fd7d3e0bdbb65ef6306f   \n",
       "...                                  ...   \n",
       "135101  4c6519d965020abc048521dfa837b9bb   \n",
       "135102  e56ec342fc599ebb4ed89655eb6f03aa   \n",
       "135103  4c6519d965020abc048521dfa837b9bb   \n",
       "135104  4c6519d965020abc048521dfa837b9bb   \n",
       "135105  e56ec342fc599ebb4ed89655eb6f03aa   \n",
       "\n",
       "                                       media media_type  \\\n",
       "0                                        NaN        NaN   \n",
       "1                                        NaN        NaN   \n",
       "2       94dca4cda503100ebfda7ce2bcc060eb.jpg  image/jpg   \n",
       "3                                        NaN        NaN   \n",
       "4                                        NaN        NaN   \n",
       "...                                      ...        ...   \n",
       "135101  1e57044095e6cb86bc7373b1a6bdf035.jpg  image/jpg   \n",
       "135102  c59e2cebce8773795fb965bdbcc4d277.jpg        url   \n",
       "135103  3811191d6ad4e71cb7e492bf6ef22a8e.jpg  image/jpg   \n",
       "135104  9dd3b338a07226a04f97df82fbbcb36b.jpg  image/jpg   \n",
       "135105  25e43b6a58b848c43ad5b5f9e979822a.jpg        url   \n",
       "\n",
       "                                                media_url  has_media  \\\n",
       "0                                                     NaN      False   \n",
       "1                                                     NaN      False   \n",
       "2                                                     NaN       True   \n",
       "3                                                     NaN      False   \n",
       "4                   www.marketingdigitalparavencer.com.br      False   \n",
       "...                                                   ...        ...   \n",
       "135101                                                NaN       True   \n",
       "135102  https://terrabrasilnoticias.com/2022/11/deputa...       True   \n",
       "135103            https://t.me/Manager_Marcus_Chat_Up_Now       True   \n",
       "135104            https://t.me/Manager_Marcus_Chat_Up_Now       True   \n",
       "135105  https://terrabrasilnoticias.com/2022/11/bndes-...       True   \n",
       "\n",
       "        has_media_url  trava_zap  \\\n",
       "0               False      False   \n",
       "1               False      False   \n",
       "2               False      False   \n",
       "3               False      False   \n",
       "4                True      False   \n",
       "...               ...        ...   \n",
       "135101          False      False   \n",
       "135102           True      False   \n",
       "135103           True      False   \n",
       "135104           True      False   \n",
       "135105           True      False   \n",
       "\n",
       "                                   text_content_anonymous  ...  media_name  \\\n",
       "0       Então é Fato Renato o áudio que eu ouvi no wha...  ...         NaN   \n",
       "1       É isso, nossa parte já foi quase toda feita. N...  ...         NaN   \n",
       "2                GENTE ACHEI ELES EM UMA SEITA MAÇONÁRICA  ...         NaN   \n",
       "3       *SE ALGUÉM TE PERGUNTAR O QUE FOI QUE BOLSONAR...  ...         NaN   \n",
       "4       O Deputado Federal pelo NOVO e que foi candida...  ...         NaN   \n",
       "...                                                   ...  ...         ...   \n",
       "135101  SOMOS TRADERS PROFISSIONAIS COM MAIS DE 20 ANO...  ...         NaN   \n",
       "135102  Deputado é reeleito nos Estados Unidos, mas mo...  ...         NaN   \n",
       "135103  ENVIE SEU PEDIDO !!!\\n\\nOI ?\\n\\nOLÁ ?\\n\\nQUÃO?...  ...         NaN   \n",
       "135104  NOVOS MEMBROS SEMPRE CLICAM NO LINK DO ADMINIS...  ...         NaN   \n",
       "135105  BNDES tem lucro de R$ 9,6 bilhões no terceiro ...  ...         NaN   \n",
       "\n",
       "                               media_md5  caracteres  words  viral sharings  \\\n",
       "0                                    NaN         110     20  False      1.0   \n",
       "1                                    NaN         350     59  False      1.0   \n",
       "2       94dca4cda503100ebfda7ce2bcc060eb          40      7  False      1.0   \n",
       "3                                    NaN        3669    618  False      1.0   \n",
       "4                                    NaN        1242    153  False      1.0   \n",
       "...                                  ...         ...    ...    ...      ...   \n",
       "135101  1e57044095e6cb86bc7373b1a6bdf035         140     23   True     13.0   \n",
       "135102  c59e2cebce8773795fb965bdbcc4d277         162     13  False      3.0   \n",
       "135103  3811191d6ad4e71cb7e492bf6ef22a8e         287     42   True     63.0   \n",
       "135104  9dd3b338a07226a04f97df82fbbcb36b         254     28   True     12.0   \n",
       "135105  25e43b6a58b848c43ad5b5f9e979822a         152     12  False      2.0   \n",
       "\n",
       "       sentiment is_misinformation word_count  \\\n",
       "0              0             False         20   \n",
       "1             -1             False         59   \n",
       "2              0             False          7   \n",
       "3              1              True        618   \n",
       "4             -1             False        153   \n",
       "...          ...               ...        ...   \n",
       "135101         0             False         23   \n",
       "135102         0             False         13   \n",
       "135103         0             False         42   \n",
       "135104         0             False         28   \n",
       "135105         1             False         12   \n",
       "\n",
       "                                                  message  \n",
       "0       Então é Fato Renato o áudio que eu ouvi no wha...  \n",
       "1       É isso, nossa parte já foi quase toda feita. N...  \n",
       "2                GENTE ACHEI ELES EM UMA SEITA MAÇONÁRICA  \n",
       "3       *SE ALGUÉM TE PERGUNTAR O QUE FOI QUE BOLSONAR...  \n",
       "4       O Deputado Federal pelo NOVO e que foi candida...  \n",
       "...                                                   ...  \n",
       "135101  SOMOS TRADERS PROFISSIONAIS COM MAIS DE 20 ANO...  \n",
       "135102  Deputado é reeleito nos Estados Unidos, mas mo...  \n",
       "135103  ENVIE SEU PEDIDO !!!\\n\\nOI ?\\n\\nOLÁ ?\\n\\nQUÃO?...  \n",
       "135104  NOVOS MEMBROS SEMPRE CLICAM NO LINK DO ADMINIS...  \n",
       "135105  BNDES tem lucro de R$ 9,6 bilhões no terceiro ...  \n",
       "\n",
       "[135106 rows x 27 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Abre do aquivo CSV e printa alguns elementos\n",
    "df = pd.read_csv(\"/home/raylander/Desktop/EDA/Lista 2/fakeTelegram.BR_2022_tratado.csv\")\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "502cd76f",
   "metadata": {},
   "source": [
    "### b)  Remova os trava-zaps. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6db6176",
   "metadata": {},
   "source": [
    "### c)  Remover textos com menos de 5 palavras.  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d67d1ee4",
   "metadata": {},
   "source": [
    "#### Tratamentos realizados na lista aterior aproveitados para a lista atual."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "009a1878",
   "metadata": {},
   "source": [
    "### d)  Monte os grafos solicitados a seguir. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc2855e5",
   "metadata": {},
   "source": [
    "## NetworkX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd1e311c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extração de Embedings\n",
    "\n",
    "model = SentenceTransformer('all-MiniLM-L6-v2')  # leve e bom para similaridade\n",
    "df['embedding'] = df['message'].apply(lambda x: model.encode(x, convert_to_tensor=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3fe489a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inicializa o grafo\n",
    "G = nx.Graph()\n",
    "\n",
    "# Agrupa os dados\n",
    "grouped = df.groupby(['id_group_anonymous'])\n",
    "threshold = 0.75\n",
    "\n",
    "for group_id, group_df in grouped:\n",
    "    # if len(group_df) > 50:\n",
    "    #     group_df = group_df.sample(n=50, random_state=42)\n",
    "\n",
    "    users = group_df['id_member_anonymous'].unique()\n",
    "    embeddings = group_df[\"embedding\"].tolist()\n",
    "    n = len(users)\n",
    "\n",
    "    for i in range(n):\n",
    "        for j in range(i+1, n):\n",
    "            sim = util.cos_sim(embeddings[i], embeddings[j]).item()\n",
    "            if sim >= threshold:\n",
    "                u1, u2 = users[i], users[j]\n",
    "\n",
    "                # Adiciona os nós (se não existirem)\n",
    "                G.add_node(u1)\n",
    "                G.add_node(u2)\n",
    "\n",
    "                # Se a aresta já existe, incrementa o peso\n",
    "                if G.has_edge(u1, u2):\n",
    "                    G[u1][u2]['weight'] += 1\n",
    "                else:\n",
    "                    G.add_edge(u1, u2, weight=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08ed25cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: When  cdn_resources is 'local' jupyter notebook has issues displaying graphics on chrome/safari. Use cdn_resources='in_line' or cdn_resources='remote' if you have issues viewing graphics in a notebook.\n",
      "grafo.html\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Visualizar no PyVis\n",
    "net = Network(notebook=True)\n",
    "net.from_nx(G)\n",
    "# Mostra no notebook\n",
    "net.show('grafos/grafo_geral_networkx.html')\n",
    "\n",
    "# Abre no navegador\n",
    "webbrowser.open('grafos/grafo_geral_networkx.html')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2804eb72",
   "metadata": {},
   "source": [
    "![Texto alternativo](imagens/graph_geral_networkx.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4c7d0f61",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filtra mensagens virais\n",
    "viral_df = df[df['viral'] == True]\n",
    "\n",
    "# Agrupa por grupo e conteúdo da mensagem\n",
    "grouped = viral_df.groupby(['id_group_anonymous', 'text_content_anonymous'])\n",
    "\n",
    "# Inicializa o grafo\n",
    "GV = nx.Graph()\n",
    "\n",
    "# Cria relacionamentos entre usuários que compartilharam a mesma mensagem viral\n",
    "for (group_id, message), group_df in grouped:\n",
    "    # if len(group_df) > 5:\n",
    "    #     group_df = group_df.sample(n=5, random_state=42)\n",
    "    users = group_df['id_member_anonymous'].unique()\n",
    "    n = len(users)\n",
    "\n",
    "    for i in range(n):\n",
    "        for j in range(i + 1, n):\n",
    "            u1, u2 = users[i], users[j]\n",
    "\n",
    "            # Adiciona nós (caso ainda não existam)\n",
    "            GV.add_node(u1)\n",
    "            GV.add_node(u2)\n",
    "\n",
    "            # Incrementa peso se já existe a aresta\n",
    "            if GV.has_edge(u1, u2):\n",
    "                GV[u1][u2]['weight'] += 1\n",
    "            else:\n",
    "                GV.add_edge(u1, u2, weight=1)\n",
    "\n",
    "# print(f\"Grafo criado com {G.number_of_nodes()} nós e {G.number_of_edges()} arestas.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d79c7d03",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: When  cdn_resources is 'local' jupyter notebook has issues displaying graphics on chrome/safari. Use cdn_resources='in_line' or cdn_resources='remote' if you have issues viewing graphics in a notebook.\n",
      "grafos/grafo_viral_networkx.html\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Visualizar no PyVis\n",
    "net = Network(notebook=True)\n",
    "net.from_nx(GV)\n",
    "# Mostra no notebook\n",
    "net.show('grafos/grafo_viral_networkx.html')\n",
    "\n",
    "# Abre no navegador\n",
    "webbrowser.open('grafos/grafo_viral_networkx.html')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab361c52",
   "metadata": {},
   "source": [
    "![Texto alternativo](imagens/graph_viral_networkx.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "28d74fb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filtrar somente mensagens de desinformação\n",
    "misinfo_df = df[df['is_misinformation'] == True]\n",
    "\n",
    "# Agrupar por grupo e conteúdo da mensagem\n",
    "grouped = misinfo_df.groupby(['id_group_anonymous', 'text_content_anonymous'])\n",
    "\n",
    "# Criar grafo\n",
    "GM = nx.Graph()\n",
    "\n",
    "# Criar relacionamentos entre usuários que compartilharam a mesma mensagem de desinformação\n",
    "for (group_id, message), group_df in grouped:\n",
    "    # if len(group_df) > 10:\n",
    "    #     group_df = group_df.sample(n=10, random_state=42)\n",
    "    users = group_df['id_member_anonymous'].unique()\n",
    "    n = len(users)\n",
    "\n",
    "    for i in range(n):\n",
    "        for j in range(i + 1, n):\n",
    "            u1, u2 = users[i], users[j]\n",
    "\n",
    "            # Adicionar nós (se ainda não existirem)\n",
    "            GM.add_node(u1)\n",
    "            GM.add_node(u2)\n",
    "\n",
    "            # Se já existe uma aresta, incrementa o peso\n",
    "            if GM.has_edge(u1, u2):\n",
    "                GM[u1][u2]['weight'] += 1\n",
    "            else:\n",
    "                GM.add_edge(u1, u2, weight=1)\n",
    "\n",
    "# print(f\"Grafo criado com {G.number_of_nodes()} nós e {G.number_of_edges()} arestas.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "676d5238",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: When  cdn_resources is 'local' jupyter notebook has issues displaying graphics on chrome/safari. Use cdn_resources='in_line' or cdn_resources='remote' if you have issues viewing graphics in a notebook.\n",
      "grafos/grafo_desinformacao_networkx.html\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Visualizar no PyVis\n",
    "net = Network(notebook=True)\n",
    "net.from_nx(GM)\n",
    "# Mostra no notebook\n",
    "net.show('grafos/grafo_desinformacao_networkx.html')\n",
    "\n",
    "# Abre no navegador\n",
    "webbrowser.open('grafos/grafo_desinformacao_networkx.html')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "399adf1a",
   "metadata": {},
   "source": [
    "![Texto alternativo](imagens/graph_desinformacao_networkx.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60500ac5",
   "metadata": {},
   "source": [
    "#### Monte uma tabela contendo a quantidade de nós e a quantidade de arestas para cada grafo (mensagens gerais, mensagens virais e mensagens com desinformação). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f984279c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mensagens Iguais: 3751 nós, 51216 arestas\n",
      "Mensagens Virais: 1139 nós, 3192 arestas\n",
      "Desinformação: 472 nós, 794 arestas\n"
     ]
    }
   ],
   "source": [
    "# Extrura os grafos como dicionário e printa número de nós e arestas\n",
    "graphs = {\n",
    "    \"Mensagens Iguais\": G,\n",
    "    \"Mensagens Virais\": GV,\n",
    "    \"Desinformação\": GM\n",
    "}\n",
    "\n",
    "for name, G in graphs.items():\n",
    "    print(f\"{name}: {G.number_of_nodes()} nós, {G.number_of_edges()} arestas\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a573d39f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Função de similaridade de cosseno\n",
    "def cos_sim(a, b):\n",
    "    # Calcula a similaridade de cosseno entre dois vetores a e b\n",
    "    a = to_vec(a); b = to_vec(b)\n",
    "    # Calcula o denominador da fórmula de similaridade de cosseno\n",
    "    denom = (np.linalg.norm(a) * np.linalg.norm(b))\n",
    "    # Verifica se o denominador é zero para evitar divisão por zero\n",
    "    if denom == 0:\n",
    "        return 0.0\n",
    "    # Retorna a similaridade de cosseno\n",
    "    return float(np.dot(a, b) / denom)\n",
    "\n",
    "# Converte embedding para numpy array CPU\n",
    "def to_vec(x):    \n",
    "    try:\n",
    "        # Verifica se é um tensor do PyTorch\n",
    "        if isinstance(x, torch.Tensor):\n",
    "            # Move para CPU se estiver em GPU\n",
    "            if x.is_cuda:\n",
    "                x = x.cpu()\n",
    "            # Retorna numpy array\n",
    "            return x.detach().numpy().astype(float)\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "    # verifica se já é numpy array\n",
    "    if isinstance(x, np.ndarray):\n",
    "        # Retorna numpy array\n",
    "        return x.astype(float)\n",
    "\n",
    "    # fallback: lista ou outro iterável\n",
    "    return np.array(x, dtype=float)\n",
    "\n",
    "\n",
    "# -------------------\n",
    "# 1) Rapid Retweet Network - (RRN) \n",
    "# Retorna grafo G_rrn (nx.Graph) onde arestas entre usuários indicam que ambos encaminharam a mesma mensagem dentro de time_window_seconds.\n",
    "# Construção: liga usuários que *compartilharam/encaminharam* a mesma message_id dentro de uma janela curta.\n",
    "# Parâmetros: time_window_seconds (int) — janela de \"rapid\" (ex: 60s, 300s)\n",
    "# -------------------\n",
    "def build_rrn(df, time_col='timestamp', msg_col='message_id', user_col='id_member_anonymous', time_window_seconds=10, min_weight=1):\n",
    "    print(f\"[RRN] Construindo RRN com janela de {time_window_seconds} segundos...\")\n",
    "    # Verifica se as colunas necessárias existem\n",
    "    if msg_col not in df.columns or time_col not in df.columns:\n",
    "        print(f\"[RRN] Atenção: colunas '{msg_col}' ou '{time_col}' ausentes. RRN exigirá message_id e timestamp.\")\n",
    "        return nx.Graph()\n",
    "    \n",
    "    print(f\"[RRN] Agrupando por '{msg_col}' e construindo arestas...\")\n",
    "\n",
    "    # Inicializa grafo\n",
    "    G = nx.Graph()\n",
    "    # Define a janela de tempo\n",
    "    window = timedelta(seconds=time_window_seconds)\n",
    "\n",
    "    # agrupa por message_id\n",
    "    for msg, group in df.groupby(msg_col):\n",
    "        # Ignora mensagens nulas\n",
    "        if pd.isna(msg):\n",
    "            continue\n",
    "        # Ordena por tempo\n",
    "        group_sorted = group.sort_values(time_col)\n",
    "        times = group_sorted[time_col].tolist()\n",
    "        users = group_sorted[user_col].tolist()\n",
    "        # Janela móvel: para cada par dentro da janela adiciona aresta\n",
    "        n = len(users)\n",
    "        for i in range(n):\n",
    "            for j in range(i+1, n):\n",
    "                # Verifica se a diferença de tempo está dentro da janela\n",
    "                if (times[j] - times[i]) <= window:\n",
    "                    # Adiciona ou incrementa aresta\n",
    "                    u1, u2 = users[i], users[j]\n",
    "                    # Evita auto-loops\n",
    "                    if u1 == u2: \n",
    "                        continue\n",
    "                    # Se a aresta já existe, incrementa o peso\n",
    "                    if G.has_edge(u1, u2):\n",
    "                        G[u1][u2]['weight'] += 1\n",
    "                    # Inicia aresta com peso 1\n",
    "                    else:\n",
    "                        G.add_edge(u1, u2, weight=1)\n",
    "                else:\n",
    "                    # Como times está ordenado, se j ficou fora da janela para i, todos seguintes também estarão\n",
    "                    break\n",
    "    \n",
    "    print(f\"[RRN] Grafo RRN criado com {G.number_of_nodes()} nós e {G.number_of_edges()} arestas.\")\n",
    "\n",
    "    # Remove arestas com peso < min_weight (opcional)\n",
    "    if min_weight > 1:\n",
    "        # Remove arestas com peso menor que min_weight\n",
    "        to_remove = [(u,v) for u,v,d in G.edges(data=True) if d.get('weight',1) < min_weight]\n",
    "        # Remove as arestas identificadas\n",
    "        G.remove_edges_from(to_remove)\n",
    "    return G\n",
    "\n",
    "# -------------------\n",
    "# 2) Similar Tweet Network - STN \n",
    "# Retorna grafo G_stn (nx.Graph) onde arestas entre usuários indicam que ambos postaram mensagens similares (por embeddings) acima de threshold.\n",
    "# Construção: arestas entre usuários com mensagens \"semelhantes\" (por embeddings ou texto).\n",
    "# Parâmetros: threshold (float) — similaridade de cosseno mínima\n",
    "# -------------------\n",
    "def build_stn(df, user_col='id_member_anonymous', emb_col='embedding', threshold=0.75, topk=None):\n",
    "    print(f\"[STN] Construindo STN com threshold de similaridade {threshold}...\")\n",
    "    # Preparar lista por usuário: (user -> list of embeddings)\n",
    "    if emb_col not in df.columns:\n",
    "        print(f\"[STN] Atenção: coluna '{emb_col}' ausente. STN usando texto nulo.\")\n",
    "        return nx.Graph()\n",
    "\n",
    "    print(f\"[STN] Agrupando por '{user_col}' e coletando embeddings...\")\n",
    "    # construir dicionário user -> list of embeddings\n",
    "    user_embs = defaultdict(list)\n",
    "    # Percorre o DataFrame e coleta embeddings por usuário\n",
    "    for _, row in df.iterrows():\n",
    "        u = row[user_col]\n",
    "        emb = row[emb_col]\n",
    "        # Ignora embeddings nulos\n",
    "        if emb is None:\n",
    "            continue\n",
    "        # Adiciona embedding convertido para numpy array\n",
    "        user_embs[u].append(to_vec(emb))\n",
    "\n",
    "    # Armazena uma lista de usuários\n",
    "    users = list(user_embs.keys())\n",
    "    # Instancia o grafo\n",
    "    G = nx.Graph()\n",
    "    # Adiciona nós e arestas por similaridade\n",
    "    print(f\"[STN] Comparando embeddings entre {len(users)} usuários...\")\n",
    "    # Adiciona arestas: qualquer par de embeddings de usuário A e B acima do threshold => add/incrementa\n",
    "    for i in range(len(users)):\n",
    "        for j in range(i+1, len(users)):\n",
    "            # Armazena o par de usuários\n",
    "            u1 = users[i]; u2 = users[j]\n",
    "            # Inicializa peso a ser adicionado\n",
    "            added_weight = 0\n",
    "            # Pega embeddings dos usuários\n",
    "            embs1 = user_embs[u1]\n",
    "            embs2 = user_embs[u2]\n",
    "            # Opicional crop to topk\n",
    "            if topk:\n",
    "                embs1 = embs1[:topk]\n",
    "                embs2 = embs2[:topk]\n",
    "            # Compara todos os pares de embeddings\n",
    "            for e1 in embs1:\n",
    "                for e2 in embs2:\n",
    "                    # Calcula similaridade de cosseno\n",
    "                    s = cos_sim(e1, e2)\n",
    "                    # Verifica se está acima do threshold\n",
    "                    if s >= threshold:\n",
    "                        # Incrementa peso para a aresta entre os usuários\n",
    "                        added_weight += 1\n",
    "            # Adiciona aresta se peso > 0\n",
    "            if added_weight > 0:\n",
    "                # Adiciona ou incrementa aresta\n",
    "                if G.has_edge(u1, u2):\n",
    "                    G[u1][u2]['weight'] += added_weight\n",
    "                else:\n",
    "                    G.add_edge(u1, u2, weight=added_weight)\n",
    "    return G\n",
    "\n",
    "# -------------------\n",
    "# 3) Combinação RRN + STN\n",
    "# Retorna grafo Gc (nx.Graph) combinando G_rrn e G_stn por método escolhido.\n",
    "# Opções: union (soma pesos), intersection (multiplica / keep only if both)\n",
    "# -------------------\n",
    "def combine_graphs(G_rrn, G_stn, method='union', rrn_weight_factor=1.0, stn_weight_factor=1.0):\n",
    "    print(f\"[COMBINE] Combinando grafos RRN e STN usando método '{method}'...\")\n",
    "    # Inicializa grafo combinado\n",
    "    Gc = nx.Graph()\n",
    "    # Adiciona nós de ambos\n",
    "    for G in (G_rrn, G_stn):\n",
    "        for n in G.nodes():\n",
    "            Gc.add_node(n)\n",
    "\n",
    "    print(f\"[COMBINE] Número de nós no grafo combinado: {Gc.number_of_nodes()}\")\n",
    "    # Union: soma\n",
    "    if method == 'union':\n",
    "        # Adiciona arestas do RRN\n",
    "        for (u,v,data) in list(G_rrn.edges(data=True)):\n",
    "            # Calcula peso com fator\n",
    "            w = data.get('weight',1) * rrn_weight_factor\n",
    "            # Adiciona ou incrementa aresta\n",
    "            Gc.add_edge(u,v, weight = Gc[u][v]['weight'] + w if Gc.has_edge(u,v) else w)\n",
    "        # Adiciona arestas do STN\n",
    "        for (u,v,data) in list(G_stn.edges(data=True)):\n",
    "            # Calcula peso com fator\n",
    "            w = data.get('weight',1) * stn_weight_factor\n",
    "            # Adiciona ou incrementa aresta\n",
    "            Gc.add_edge(u,v, weight = Gc[u][v]['weight'] + w if Gc.has_edge(u,v) else w)\n",
    "    # Intersection: mantém somente arestas presentes em ambos\n",
    "    elif method == 'intersection':\n",
    "        # Adiciona arestas presentes em ambos\n",
    "        for (u,v,data) in list(G_rrn.edges(data=True)):\n",
    "            # Verifica se a aresta também está no STN\n",
    "            if G_stn.has_edge(u,v):\n",
    "                # Calcula peso médio ponderado do RRN e STN\n",
    "                w_rrn = data.get('weight',1) * rrn_weight_factor\n",
    "                # Pega peso do STN\n",
    "                w_stn = G_stn[u][v].get('weight',1) * stn_weight_factor\n",
    "                # Calcula peso médio ponderado do RRN e STN\n",
    "                w = (w_rrn + w_stn) / 2.0\n",
    "                # Adiciona aresta com peso médio ponderado\n",
    "                Gc.add_edge(u,v, weight=w)\n",
    "    # Max: mantém arestas de ambos com peso = max(...)\n",
    "    elif method == 'max':\n",
    "        # Adiciona arestas do RRN\n",
    "        for (u,v,data) in list(G_rrn.edges(data=True)):\n",
    "            Gc.add_edge(u,v, weight=data.get('weight',1) * rrn_weight_factor)\n",
    "        # Adiciona arestas do STN\n",
    "        for (u,v,data) in list(G_stn.edges(data=True)):\n",
    "            w_new = data.get('weight',1) * stn_weight_factor\n",
    "            # Se a aresta já existe, mantém o máximo\n",
    "            if Gc.has_edge(u,v):\n",
    "                Gc[u][v]['weight'] = max(Gc[u][v]['weight'], w_new)\n",
    "            else:\n",
    "                Gc.add_edge(u,v, weight=w_new)\n",
    "    else:\n",
    "        raise ValueError(\"method must be 'union', 'intersection' or 'max'\")\n",
    "\n",
    "    return Gc\n",
    "\n",
    "# -------------------\n",
    "# 4) Método baseado em redes bipartidas (usuário <-> mensagem)\n",
    "# Retorna G_user (nx.Graph) - projeção do bipartite user-message.\n",
    "# Constrói projeção do bipartite user-message para user-user com peso = número de mensagens compartilhadas.\n",
    "# -------------------\n",
    "def build_bipartite_projection(df, user_col='id_member_anonymous', msg_col='message_id'):\n",
    "    print(f\"[BIPARTITE] Construindo projeção bipartite user-message...\")\n",
    "    # Verifica se a coluna de mensagens existe\n",
    "    if msg_col not in df.columns:\n",
    "        print(f\"[BIPARTITE] coluna '{msg_col}' ausente. Não é possível construir bipartite projection.\")\n",
    "        return nx.Graph()\n",
    "\n",
    "    print(f\"[BIPARTITE] Agrupando mensagens por usuários...\")\n",
    "    # Construir dicionário message -> set(users)\n",
    "    msg_users = defaultdict(set)\n",
    "    # Percorre o DataFrame e coleta usuários por mensagem\n",
    "    for _, row in df.iterrows():\n",
    "        msg = row[msg_col]\n",
    "        u = row[user_col]\n",
    "        # Ignora mensagens nulas\n",
    "        if pd.isna(msg):\n",
    "            continue\n",
    "        # Adiciona usuário ao conjunto da mensagem\n",
    "        msg_users[msg].add(u)\n",
    "\n",
    "    print(f\"[BIPARTITE] Construindo projeção user-user...\")\n",
    "    # Inicializa grafo user-user\n",
    "    G = nx.Graph()\n",
    "    # Adiciona arestas entre usuários que compartilharam mensagens\n",
    "    for msg, users in msg_users.items():\n",
    "        # Converte conjunto de usuários para lista\n",
    "        users = list(users)\n",
    "        # Adiciona nós\n",
    "        for u in users:\n",
    "            if not G.has_node(u):\n",
    "                G.add_node(u)\n",
    "        # Adiciona arestas entre todos os pares de usuários que compartilharam a mensagem\n",
    "        for (u1,u2) in combinations(users, 2):\n",
    "            if G.has_edge(u1,u2):\n",
    "                G[u1][u2]['weight'] += 1\n",
    "            else:\n",
    "                G.add_edge(u1,u2, weight=1)\n",
    "    return G\n",
    "\n",
    "# -------------------\n",
    "# 5) Método de Medição da Coordenação (score numérico por usuário e por subgrafo)\n",
    "# Retorna dict com métricas por comunidade e por usuário.\n",
    "# Exemplos de medidas:\n",
    "#   - Pairwise Coordination Score: média ponderada dos pesos entre pares dentro de uma comunidade\n",
    "#   - Group Coordination Index: (sum weights within group) / (possible edges)\n",
    "# -------------------\n",
    "def coordination_scores_for_partition(G, partition):\n",
    "    print(f\"[COORDINATION] Calculando scores de coordenação para partição com {len(partition)} comunidades...\")\n",
    "    results = []\n",
    "    # Para cada comunidade na partição\n",
    "    for part in partition:\n",
    "        # Extrai subgrafo da comunidade\n",
    "        nodes = list(part)\n",
    "        subG = G.subgraph(nodes)\n",
    "        m = subG.number_of_edges()\n",
    "        # Soma dos pesos das arestas internas\n",
    "        sum_w = sum(d.get('weight',1) for _,_,d in subG.edges(data=True))\n",
    "        # Número de nós na comunidade\n",
    "        n = len(nodes)\n",
    "        # Número de arestas possíveis\n",
    "        possible = n*(n-1)/2 if n>1 else 1\n",
    "        # Calcula índice de coordenação da comunidade\n",
    "        community_coord_index = sum_w / possible\n",
    "        # Calcula peso médio por par de usuários na comunidade\n",
    "        avg_pair_weight = (sum_w / m) if m>0 else 0.0\n",
    "        # Calcula score de coordenação por usuário na comunidade\n",
    "        user_scores = {}\n",
    "        for node in nodes:\n",
    "            # Soma dos pesos das arestas internas do nó\n",
    "            internal_weight = sum(data.get('weight',1) for _,_,data in subG.edges(node, data=True))\n",
    "            # normaliza por (n-1) para ter 0..inf; podemos dividir por (n-1) para escala\n",
    "            user_scores[node] = internal_weight / max(1, (n-1))\n",
    "        # Armazena resultados da comunidade\n",
    "        results.append({\n",
    "            'nodes': nodes,\n",
    "            'n': n,\n",
    "            'edges': m,\n",
    "            'sum_weight': sum_w,\n",
    "            'community_coord_index': community_coord_index,\n",
    "            'avg_pair_weight': avg_pair_weight,\n",
    "            'user_scores': user_scores\n",
    "        })\n",
    "    return results\n",
    "\n",
    "# -------------------\n",
    "# 6) Particionamento e métricas (Modularity + Partition Quality)\n",
    "# Retorna dict com 'partition', 'modularity', 'coverage', 'performance', 'partition_quality'.\n",
    "# Partition Quality: definimos aqui como (coverage + performance) / 2 (medida combinada).\n",
    "# -------------------\n",
    "def detect_communities_and_evaluate(G, method='greedy'):\n",
    "    print(f\"[COMMUNITY] Detectando comunidades usando método '{method}'...\")\n",
    "    # G vazio\n",
    "    if G.number_of_nodes() == 0:\n",
    "        return {'partition':[], 'modularity':0.0, 'coverage':0.0, 'performance':0.0, 'partition_quality':0.0}\n",
    "\n",
    "    # Detecção de comunidades\n",
    "    if method == 'greedy':\n",
    "        partition = list(nx_comm.greedy_modularity_communities(G, weight='weight'))\n",
    "    # Label propagation\n",
    "    elif method == 'label':\n",
    "        partition = list(nx_comm.asyn_lpa_communities(G, weight='weight'))\n",
    "    else:\n",
    "        raise ValueError(\"method must be 'greedy' or 'label'\")\n",
    "\n",
    "    print(f\"[COMMUNITY] Detectadas {len(partition)} comunidades.\")\n",
    "    # Modularity\n",
    "    mod = nx_quality.modularity(G, partition, weight='weight')\n",
    "    cov, perf = nx_quality.partition_quality(G, partition)\n",
    "    # Partition Quality\n",
    "    part_quality = (cov + perf) / 2.0\n",
    "    return {\n",
    "        'partition': partition,\n",
    "        'modularity': mod,\n",
    "        'coverage': cov,\n",
    "        'performance': perf,\n",
    "        'partition_quality': part_quality\n",
    "    }\n",
    "\n",
    "# -------------------\n",
    "# 7) Pipeline para executar os 3 cenários pedido + bipartite e medir tudo\n",
    "# Cenários (assumidos aqui):\n",
    "#   Scenario A: STN-only (similar messages)\n",
    "#   Scenario B: RRN-only (rapid shares)\n",
    "#   Scenario C: Combination (RRN + STN union)\n",
    "# Você pode alterar para os cenários que desejar.\n",
    "# -------------------\n",
    "def run_all_scenarios(df,\n",
    "                      time_col='timestamp', msg_col='message_id', user_col='id_member_anonymous', emb_col='embedding',\n",
    "                      rrn_window_seconds=10, stn_threshold=0.75, combine_method='union', graph='geral'):\n",
    "    results = {}\n",
    "\n",
    "    # STN\n",
    "    G_stn = build_stn(df, user_col=user_col, emb_col=emb_col, threshold=stn_threshold)\n",
    "    res_stn = detect_communities_and_evaluate(G_stn)\n",
    "    res_stn['graph'] = G_stn\n",
    "    results['STN'] = res_stn\n",
    "    # Extrai o grafo para o gephi\n",
    "    nx.write_gexf(G_stn, f\"stn_graph_{graph}.gexf\")\n",
    "    # Visualizar no PyVis\n",
    "    net = Network(notebook=True)\n",
    "    net.from_nx(G_stn)\n",
    "    # Mostra no notebook\n",
    "    net.show(f'grafos/grafo_{graph}_networkx_stn.html')\n",
    "    # Abre no navegador\n",
    "    webbrowser.open(f'grafos/grafo_{graph}_networkx_stn.html')\n",
    "\n",
    "    # RRN\n",
    "    G_rrn = build_rrn(df, time_col=time_col, msg_col=msg_col, user_col=user_col, time_window_seconds=rrn_window_seconds)\n",
    "    res_rrn = detect_communities_and_evaluate(G_rrn)\n",
    "    res_rrn['graph'] = G_rrn\n",
    "    results['RRN'] = res_rrn\n",
    "    # Extrai o grafo para o gephi\n",
    "    nx.write_gexf(G_rrn, f\"rrn_graph_{graph}.gexf\")\n",
    "    # Visualizar no PyVis\n",
    "    net = Network(notebook=True)\n",
    "    net.from_nx(G_rrn)\n",
    "    # Mostra no notebook\n",
    "    net.show(f'grafos/grafo_{graph}_networkx_rrn.html')\n",
    "    # Abre no navegador\n",
    "    webbrowser.open(f'grafos/grafo_{graph}_networkx_rrn.html')\n",
    "    \n",
    "\n",
    "    # Combined\n",
    "    G_comb = combine_graphs(G_rrn, G_stn, method=combine_method)\n",
    "    res_comb = detect_communities_and_evaluate(G_comb)\n",
    "    res_comb['graph'] = G_comb\n",
    "    results['COMBINED'] = res_comb\n",
    "    # Extrai o grafo para o gephi\n",
    "    nx.write_gexf(G_comb, f\"combined_graph_{graph}.gexf\")\n",
    "    # Visualizar no PyVis\n",
    "    net = Network(notebook=True)\n",
    "    net.from_nx(G_comb)\n",
    "    # Mostra no notebook\n",
    "    net.show(f'grafos/grafo_{graph}_networkx_combined.html')\n",
    "    # Abre no navegador\n",
    "    webbrowser.open(f'grafos/grafo_{graph}_networkx_combined.html')\n",
    "\n",
    "    # Bipartite projection\n",
    "    G_bip = build_bipartite_projection(df, user_col=user_col, msg_col=msg_col)\n",
    "    res_bip = detect_communities_and_evaluate(G_bip)\n",
    "    res_bip['graph'] = G_bip\n",
    "    results['BIPARTITE'] = res_bip\n",
    "    # Extrai o grafo para o gephi\n",
    "    nx.write_gexf(G_bip, f\"bipartite_graph_{graph}.gexf\")\n",
    "    # Visualizar no PyVis\n",
    "    net = Network(notebook=True)\n",
    "    net.from_nx(G_bip)\n",
    "    # Mostra no notebook\n",
    "    net.show(f'grafos/grafo_{graph}_networkx_bipartite.html')\n",
    "    # Abre no navegador\n",
    "    webbrowser.open(f'grafos/grafo_{graph}_networkx_bipartite.html')\n",
    "\n",
    "    # Coordination measurement per detected partition (for each scenario)\n",
    "    for name, r in results.items():\n",
    "        part = r['partition']\n",
    "        r['coordination_details'] = coordination_scores_for_partition(r['graph'], part) if r['graph'].number_of_nodes() > 0 else []\n",
    "\n",
    "    return results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e260e47",
   "metadata": {},
   "source": [
    "##### Grafo Geral"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "de986627",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[STN] Construindo STN com threshold de similaridade 0.78...\n",
      "[STN] Agrupando por 'id_member_anonymous' e coletando embeddings...\n",
      "[STN] Comparando embeddings entre 10677 usuários...\n",
      "[COMMUNITY] Detectando comunidades usando método 'greedy'...\n",
      "[COMMUNITY] Detectadas 105 comunidades.\n",
      "Warning: When  cdn_resources is 'local' jupyter notebook has issues displaying graphics on chrome/safari. Use cdn_resources='in_line' or cdn_resources='remote' if you have issues viewing graphics in a notebook.\n",
      "grafos/grafo_geral_networkx_stn.html\n",
      "[RRN] Construindo RRN com janela de 120 segundos...\n",
      "[RRN] Atenção: colunas 'message_id' ou 'timestamp' ausentes. RRN exigirá message_id e timestamp.\n",
      "[COMMUNITY] Detectando comunidades usando método 'greedy'...\n",
      "Warning: When  cdn_resources is 'local' jupyter notebook has issues displaying graphics on chrome/safari. Use cdn_resources='in_line' or cdn_resources='remote' if you have issues viewing graphics in a notebook.\n",
      "grafos/grafo_geral_networkx_rrn.html\n",
      "[COMBINE] Combinando grafos RRN e STN usando método 'union'...\n",
      "[COMBINE] Número de nós no grafo combinado: 6194\n",
      "[COMMUNITY] Detectando comunidades usando método 'greedy'...\n",
      "[COMMUNITY] Detectadas 167 comunidades.\n",
      "Warning: When  cdn_resources is 'local' jupyter notebook has issues displaying graphics on chrome/safari. Use cdn_resources='in_line' or cdn_resources='remote' if you have issues viewing graphics in a notebook.\n",
      "grafos/grafo_geral_networkx_combined.html\n",
      "[BIPARTITE] Construindo projeção bipartite user-message...\n",
      "[BIPARTITE] coluna 'message_id' ausente. Não é possível construir bipartite projection.\n",
      "[COMMUNITY] Detectando comunidades usando método 'greedy'...\n",
      "Warning: When  cdn_resources is 'local' jupyter notebook has issues displaying graphics on chrome/safari. Use cdn_resources='in_line' or cdn_resources='remote' if you have issues viewing graphics in a notebook.\n",
      "grafos/grafo_geral_networkx_bipartite.html\n",
      "[COORDINATION] Calculando scores de coordenação para partição com 105 comunidades...\n",
      "[COORDINATION] Calculando scores de coordenação para partição com 167 comunidades...\n",
      "--- STN ---\n",
      "Nodes: 6194 Edges: 140809\n",
      "Modularity: 0.5557474600513528\n",
      "Partition Quality (coverage+performance)/2: 0.6055778777721204\n",
      "  Community 0: n=19, community_coord_index=1.000, sum_weight=171\n",
      "  Community 1: n=18, community_coord_index=1.000, sum_weight=153\n",
      "  Community 2: n=14, community_coord_index=1.000, sum_weight=91\n",
      "--- RRN ---\n",
      "Nodes: 0 Edges: 0\n",
      "Modularity: 0.0\n",
      "Partition Quality (coverage+performance)/2: 0.0\n",
      "--- COMBINED ---\n",
      "Nodes: 6194 Edges: 140809\n",
      "Modularity: 0.31788330780766477\n",
      "Partition Quality (coverage+performance)/2: 0.7100551461564546\n",
      "  Community 0: n=19, community_coord_index=1.000, sum_weight=171\n",
      "  Community 1: n=18, community_coord_index=1.000, sum_weight=153\n",
      "  Community 2: n=14, community_coord_index=1.000, sum_weight=91\n",
      "--- BIPARTITE ---\n",
      "Nodes: 0 Edges: 0\n",
      "Modularity: 0.0\n",
      "Partition Quality (coverage+performance)/2: 0.0\n"
     ]
    }
   ],
   "source": [
    "# -------------------\n",
    "# Usage example:\n",
    "# -------------------\n",
    "results = run_all_scenarios(df,\n",
    "                            rrn_window_seconds=120,\n",
    "                            stn_threshold=0.78,\n",
    "                            combine_method='union', graph = 'geral')\n",
    "\n",
    "# imprimir sumário\n",
    "for name, r in results.items():\n",
    "    print(f\"--- {name} ---\")\n",
    "    print(\"Nodes:\", r['graph'].number_of_nodes(), \"Edges:\", r['graph'].number_of_edges())\n",
    "    print(\"Modularity:\", r['modularity'])\n",
    "    print(\"Partition Quality (coverage+performance)/2:\", r['partition_quality'])\n",
    "    # detalhes coordenação para top communities\n",
    "    for i, cdet in enumerate(sorted(r['coordination_details'], key=lambda x: x['community_coord_index'], reverse=True)[:3]):\n",
    "        print(f\"  Community {i}: n={cdet['n']}, community_coord_index={cdet['community_coord_index']:.3f}, sum_weight={cdet['sum_weight']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2960aad9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "webbrowser.open(f'grafos/grafo_geral_networkx_stn.html')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ef52272",
   "metadata": {},
   "source": [
    "![Texto alternativo](imagens/graph_geral_networkx_stn.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3357703",
   "metadata": {},
   "outputs": [],
   "source": [
    "webbrowser.open(f'grafos/grafo_geral_networkx_rrn.html')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bf2c5d0",
   "metadata": {},
   "source": [
    "#### Não conseguiu construir grafo com um tempo de 10 segundos de diferença de uma memsagem para outra"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a13074b",
   "metadata": {},
   "outputs": [],
   "source": [
    "webbrowser.open(f'grafos/grafo_geral_networkx_combined.html')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fe9f083",
   "metadata": {},
   "source": [
    "![Texto alternativo](imagens/graph_geral_networkx_stn.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52c08230",
   "metadata": {},
   "outputs": [],
   "source": [
    "webbrowser.open(f'grafos/grafo_geral_networkx_bipartite.html')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3760a195",
   "metadata": {},
   "source": [
    "#### Não conseguiu construir um grafo, não atendeu aos critérios de construção"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "34a22689",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_metrics_geral = pd.DataFrame([\n",
    "    {\"graph_type\": name, **{k:v for k,v in res.items() if k!=\"graph\"}}\n",
    "    for name, res in results.items()\n",
    "])\n",
    "\n",
    "df_graphs_geral = pd.DataFrame([\n",
    "    {\"graph_type\": name, \"graph\": res[\"graph\"]}\n",
    "    for name, res in results.items()\n",
    "])\n",
    "\n",
    "df_metrics_geral.to_csv('community_detection_results_geral.csv', index=False)\n",
    "df_graphs_geral.to_csv('community_detection_graphs_geral.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "082e1e0e",
   "metadata": {},
   "source": [
    "#### Grafo Viral"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e583c858",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[STN] Construindo STN com threshold de similaridade 0.78...\n",
      "[STN] Agrupando por 'id_member_anonymous' e coletando embeddings...\n",
      "[STN] Comparando embeddings entre 1811 usuários...\n",
      "[COMMUNITY] Detectando comunidades usando método 'greedy'...\n",
      "[COMMUNITY] Detectadas 45 comunidades.\n",
      "Warning: When  cdn_resources is 'local' jupyter notebook has issues displaying graphics on chrome/safari. Use cdn_resources='in_line' or cdn_resources='remote' if you have issues viewing graphics in a notebook.\n",
      "grafos/grafo_viral_networkx_stn.html\n",
      "[RRN] Construindo RRN com janela de 120 segundos...\n",
      "[RRN] Atenção: colunas 'message_id' ou 'timestamp' ausentes. RRN exigirá message_id e timestamp.\n",
      "[COMMUNITY] Detectando comunidades usando método 'greedy'...\n",
      "Warning: When  cdn_resources is 'local' jupyter notebook has issues displaying graphics on chrome/safari. Use cdn_resources='in_line' or cdn_resources='remote' if you have issues viewing graphics in a notebook.\n",
      "grafos/grafo_viral_networkx_rrn.html\n",
      "[COMBINE] Combinando grafos RRN e STN usando método 'union'...\n",
      "[COMBINE] Número de nós no grafo combinado: 1704\n",
      "[COMMUNITY] Detectando comunidades usando método 'greedy'...\n",
      "[COMMUNITY] Detectadas 52 comunidades.\n",
      "Warning: When  cdn_resources is 'local' jupyter notebook has issues displaying graphics on chrome/safari. Use cdn_resources='in_line' or cdn_resources='remote' if you have issues viewing graphics in a notebook.\n",
      "grafos/grafo_viral_networkx_combined.html\n",
      "[BIPARTITE] Construindo projeção bipartite user-message...\n",
      "[BIPARTITE] coluna 'message_id' ausente. Não é possível construir bipartite projection.\n",
      "[COMMUNITY] Detectando comunidades usando método 'greedy'...\n",
      "Warning: When  cdn_resources is 'local' jupyter notebook has issues displaying graphics on chrome/safari. Use cdn_resources='in_line' or cdn_resources='remote' if you have issues viewing graphics in a notebook.\n",
      "grafos/grafo_viral_networkx_bipartite.html\n",
      "[COORDINATION] Calculando scores de coordenação para partição com 45 comunidades...\n",
      "[COORDINATION] Calculando scores de coordenação para partição com 52 comunidades...\n",
      "--- STN ---\n",
      "Nodes: 1704 Edges: 30710\n",
      "Modularity: 0.6696922645429084\n",
      "Partition Quality (coverage+performance)/2: 0.6410461808694671\n",
      "  Community 0: n=18, community_coord_index=1.000, sum_weight=153\n",
      "  Community 1: n=15, community_coord_index=1.000, sum_weight=105\n",
      "  Community 2: n=14, community_coord_index=1.000, sum_weight=91\n",
      "--- RRN ---\n",
      "Nodes: 0 Edges: 0\n",
      "Modularity: 0.0\n",
      "Partition Quality (coverage+performance)/2: 0.0\n",
      "--- COMBINED ---\n",
      "Nodes: 1704 Edges: 30710\n",
      "Modularity: 0.44793480486406534\n",
      "Partition Quality (coverage+performance)/2: 0.7421625172924424\n",
      "  Community 0: n=18, community_coord_index=1.000, sum_weight=153\n",
      "  Community 1: n=15, community_coord_index=1.000, sum_weight=105\n",
      "  Community 2: n=14, community_coord_index=1.000, sum_weight=91\n",
      "--- BIPARTITE ---\n",
      "Nodes: 0 Edges: 0\n",
      "Modularity: 0.0\n",
      "Partition Quality (coverage+performance)/2: 0.0\n"
     ]
    }
   ],
   "source": [
    "# -------------------\n",
    "# Usage example:\n",
    "# -------------------\n",
    "viral_df = df[df['viral'] == True]\n",
    "results = run_all_scenarios(viral_df,\n",
    "                            rrn_window_seconds=120,\n",
    "                            stn_threshold=0.78,\n",
    "                            combine_method='union', graph='viral')\n",
    "\n",
    "# imprimir sumário\n",
    "for name, r in results.items():\n",
    "    print(f\"--- {name} ---\")\n",
    "    print(\"Nodes:\", r['graph'].number_of_nodes(), \"Edges:\", r['graph'].number_of_edges())\n",
    "    print(\"Modularity:\", r['modularity'])\n",
    "    print(\"Partition Quality (coverage+performance)/2:\", r['partition_quality'])\n",
    "    # detalhes coordenação para top communities\n",
    "    for i, cdet in enumerate(sorted(r['coordination_details'], key=lambda x: x['community_coord_index'], reverse=True)[:3]):\n",
    "        print(f\"  Community {i}: n={cdet['n']}, community_coord_index={cdet['community_coord_index']:.3f}, sum_weight={cdet['sum_weight']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1e93c380",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "webbrowser.open(f'grafos/grafo_viral_networkx_stn.html')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e54ebfe4",
   "metadata": {},
   "source": [
    "![Texto alternativo](imagens/graph_viral_networkx_stn.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51368e63",
   "metadata": {},
   "outputs": [],
   "source": [
    "webbrowser.open(f'grafos/grafo_viral_networkx_rrn.html')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "627951d5",
   "metadata": {},
   "source": [
    "#### Não conseguiu construir grafo com um tempo de 10 segundos de diferença de uma memsagem para outra"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e174dd2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "webbrowser.open(f'grafos/grafo_viral_networkx_combined.html')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64a35598",
   "metadata": {},
   "source": [
    "![Texto alternativo](imagens/graph_viral_networkx_stn.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3180c0e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "webbrowser.open(f'grafos/grafo_viral_networkx_bipartite.html')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a440732",
   "metadata": {},
   "source": [
    "#### Não conseguiu construir um grafo, não atendeu aos critérios de construção"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "202be526",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_metrics_viral = pd.DataFrame([\n",
    "    {\"graph_type\": name, **{k:v for k,v in res.items() if k!=\"graph\"}}\n",
    "    for name, res in results.items()\n",
    "])\n",
    "\n",
    "df_graphs_viral = pd.DataFrame([\n",
    "    {\"graph_type\": name, \"graph\": res[\"graph\"]}\n",
    "    for name, res in results.items()\n",
    "])\n",
    "\n",
    "df_metrics_viral.to_csv('community_detection_results_viral.csv', index=False)\n",
    "df_graphs_viral.to_csv('community_detection_graphs_viral.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71009c36",
   "metadata": {},
   "source": [
    "#### Grafo Desinformação"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f406a76e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[STN] Construindo STN com threshold de similaridade 0.78...\n",
      "[STN] Agrupando por 'id_member_anonymous' e coletando embeddings...\n",
      "[STN] Comparando embeddings entre 2497 usuários...\n",
      "[COMMUNITY] Detectando comunidades usando método 'greedy'...\n",
      "[COMMUNITY] Detectadas 32 comunidades.\n",
      "Warning: When  cdn_resources is 'local' jupyter notebook has issues displaying graphics on chrome/safari. Use cdn_resources='in_line' or cdn_resources='remote' if you have issues viewing graphics in a notebook.\n",
      "grafos/grafo_desinformacao_networkx_stn.html\n",
      "[RRN] Construindo RRN com janela de 120 segundos...\n",
      "[RRN] Atenção: colunas 'message_id' ou 'timestamp' ausentes. RRN exigirá message_id e timestamp.\n",
      "[COMMUNITY] Detectando comunidades usando método 'greedy'...\n",
      "Warning: When  cdn_resources is 'local' jupyter notebook has issues displaying graphics on chrome/safari. Use cdn_resources='in_line' or cdn_resources='remote' if you have issues viewing graphics in a notebook.\n",
      "grafos/grafo_desinformacao_networkx_rrn.html\n",
      "[COMBINE] Combinando grafos RRN e STN usando método 'union'...\n",
      "[COMBINE] Número de nós no grafo combinado: 1624\n",
      "[COMMUNITY] Detectando comunidades usando método 'greedy'...\n",
      "[COMMUNITY] Detectadas 46 comunidades.\n",
      "Warning: When  cdn_resources is 'local' jupyter notebook has issues displaying graphics on chrome/safari. Use cdn_resources='in_line' or cdn_resources='remote' if you have issues viewing graphics in a notebook.\n",
      "grafos/grafo_desinformacao_networkx_combined.html\n",
      "[BIPARTITE] Construindo projeção bipartite user-message...\n",
      "[BIPARTITE] coluna 'message_id' ausente. Não é possível construir bipartite projection.\n",
      "[COMMUNITY] Detectando comunidades usando método 'greedy'...\n",
      "Warning: When  cdn_resources is 'local' jupyter notebook has issues displaying graphics on chrome/safari. Use cdn_resources='in_line' or cdn_resources='remote' if you have issues viewing graphics in a notebook.\n",
      "grafos/grafo_desinformacao_networkx_bipartite.html\n",
      "[COORDINATION] Calculando scores de coordenação para partição com 32 comunidades...\n",
      "[COORDINATION] Calculando scores de coordenação para partição com 46 comunidades...\n",
      "--- STN ---\n",
      "Nodes: 1624 Edges: 27613\n",
      "Modularity: 0.48395622288593293\n",
      "Partition Quality (coverage+performance)/2: 0.7086773270285063\n",
      "  Community 0: n=4, community_coord_index=1.000, sum_weight=6\n",
      "  Community 1: n=2, community_coord_index=1.000, sum_weight=1\n",
      "  Community 2: n=2, community_coord_index=1.000, sum_weight=1\n",
      "--- RRN ---\n",
      "Nodes: 0 Edges: 0\n",
      "Modularity: 0.0\n",
      "Partition Quality (coverage+performance)/2: 0.0\n",
      "--- COMBINED ---\n",
      "Nodes: 1624 Edges: 27613\n",
      "Modularity: 0.33876979566075716\n",
      "Partition Quality (coverage+performance)/2: 0.7040145911653388\n",
      "  Community 0: n=8, community_coord_index=1.000, sum_weight=28\n",
      "  Community 1: n=8, community_coord_index=1.000, sum_weight=28\n",
      "  Community 2: n=4, community_coord_index=1.000, sum_weight=6\n",
      "--- BIPARTITE ---\n",
      "Nodes: 0 Edges: 0\n",
      "Modularity: 0.0\n",
      "Partition Quality (coverage+performance)/2: 0.0\n"
     ]
    }
   ],
   "source": [
    "# -------------------\n",
    "# Usage example:\n",
    "# -------------------\n",
    "misinfo_df = df[df['is_misinformation'] == True]\n",
    "results = run_all_scenarios(misinfo_df,\n",
    "                            rrn_window_seconds=120,\n",
    "                            stn_threshold=0.78,\n",
    "                            combine_method='union', graph='desinformacao')\n",
    "\n",
    "# imprimir sumário\n",
    "for name, r in results.items():\n",
    "    print(f\"--- {name} ---\")\n",
    "    print(\"Nodes:\", r['graph'].number_of_nodes(), \"Edges:\", r['graph'].number_of_edges())\n",
    "    print(\"Modularity:\", r['modularity'])\n",
    "    print(\"Partition Quality (coverage+performance)/2:\", r['partition_quality'])\n",
    "    # detalhes coordenação para top communities\n",
    "    for i, cdet in enumerate(sorted(r['coordination_details'], key=lambda x: x['community_coord_index'], reverse=True)[:3]):\n",
    "        print(f\"  Community {i}: n={cdet['n']}, community_coord_index={cdet['community_coord_index']:.3f}, sum_weight={cdet['sum_weight']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9fcd7135",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "webbrowser.open(f'grafos/grafo_desinformacao_networkx_stn.html')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ec11a91",
   "metadata": {},
   "source": [
    "![Texto alternativo](imagens/graph_desinformacao_networkx_stn.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46b83dd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "webbrowser.open(f'grafos/grafo_desinformacao_networkx_rrn.html')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba20dd79",
   "metadata": {},
   "source": [
    "#### Não conseguiu construir grafo com um tempo de 10 segundos de diferença de uma memsagem para outra"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2147adb",
   "metadata": {},
   "outputs": [],
   "source": [
    "webbrowser.open(f'grafos/grafo_desinformacao_networkx_combined.html')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "060632df",
   "metadata": {},
   "source": [
    "![Texto alternativo](imagens/graph_desinformacao_networkx_stn.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fbf6339",
   "metadata": {},
   "outputs": [],
   "source": [
    "webbrowser.open(f'grafos/grafo_desinformacao_networkx_bipartite.html')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86544eaa",
   "metadata": {},
   "source": [
    "#### Não conseguiu construir um grafo, não atendeu aos critérios de construção"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "88bbb48c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_metrics_misinfo = pd.DataFrame([\n",
    "    {\"graph_type\": name, **{k:v for k,v in res.items() if k!=\"graph\"}}\n",
    "    for name, res in results.items()\n",
    "])\n",
    "\n",
    "df_graphs_misinfo = pd.DataFrame([\n",
    "    {\"graph_type\": name, \"graph\": res[\"graph\"]}\n",
    "    for name, res in results.items()\n",
    "])\n",
    "\n",
    "df_metrics_misinfo.to_csv('community_detection_results_misinfo.csv', index=False)\n",
    "df_graphs_misinfo.to_csv('community_detection_graphs_misinfo.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "503dd0e8",
   "metadata": {},
   "source": [
    "## Gephi"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "240a6793",
   "metadata": {},
   "source": [
    "### Gerando grafos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "4eeec7bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "nx.write_gexf(G, \"grafo_geral.gexf\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55283144",
   "metadata": {},
   "source": [
    "![Texto alternativo](imagens/gephi_geral.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b92657d",
   "metadata": {},
   "outputs": [],
   "source": [
    "nx.write_gexf(GV, \"grafo_viral.gexf\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "561bf1de",
   "metadata": {},
   "source": [
    "![Texto alternativo](imagens/gephi_viral.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a28df318",
   "metadata": {},
   "outputs": [],
   "source": [
    "nx.write_gexf(GM, \"grafo_desinformacao.gexf\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "364d9b90",
   "metadata": {},
   "source": [
    "![Texto alternativo](imagens/gephi_desinformacao.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cce9ffec",
   "metadata": {},
   "source": [
    "### Contanto quantidade de nós e arestas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8267d6c5",
   "metadata": {},
   "source": [
    "#### Nós e arestas do grafo geral"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0eff7257",
   "metadata": {},
   "source": [
    "![Texto alternativo](imagens/gephi_geral_quantidade.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "974f1bf9",
   "metadata": {},
   "source": [
    "#### Nós e arestas do grafo viral"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d89ebbb",
   "metadata": {},
   "source": [
    "![Texto alternativo](imagens/gephi_viral_quantidade.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0edeb95",
   "metadata": {},
   "source": [
    "#### Nós e arestas do grafo desinformação"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fd88c96",
   "metadata": {},
   "source": [
    "![Texto alternativo](imagens/gephi_desinformacao_quantiadade.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efdbaeb5",
   "metadata": {},
   "source": [
    "### Detecção de comportamento"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "537974ad",
   "metadata": {},
   "source": [
    "#### Geral"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "618c9935",
   "metadata": {},
   "source": [
    "![Texto alternativo](imagens/graph_geral_gephi_stn.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad5bb18d",
   "metadata": {},
   "source": [
    "#### Modularity"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a01ba56",
   "metadata": {},
   "source": [
    "![Texto alternativo](imagens/graph_geral_gephi_stn_modularity.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63379289",
   "metadata": {},
   "source": [
    "#### Viral"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61607dc1",
   "metadata": {},
   "source": [
    "![Texto alternativo](imagens/graph_geral_gephi_stn.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5d64664",
   "metadata": {},
   "source": [
    "#### Modularity"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c5b5da9",
   "metadata": {},
   "source": [
    "![Texto alternativo](imagens/graph_viral_gephi_stn_modularity.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16a675ef",
   "metadata": {},
   "source": [
    "#### Desinformação"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "297a1121",
   "metadata": {},
   "source": [
    "![Texto alternativo](imagens/graph_desinformacao_gephi_stn.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92dc39d3",
   "metadata": {},
   "source": [
    "#### Modularity"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "611486a7",
   "metadata": {},
   "source": [
    "![Texto alternativo](imagens/graph_desinformacao_gephi_stn_modularity.png)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
